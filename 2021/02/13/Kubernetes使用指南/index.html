<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="PaaS概述 PaaS(Platform as a service),平台即服务,指将软件研发的平台(或业务基础平台)作为一种服务,以SaaS的模式提交给用户.PaaS是云计算服务的其中一种模式,云计算是一种按使用量付费的模式的服务,类似一种租赁服务,服务可以是基础设施计算资源(IaaS),平台(PaaS),软件(SaaS).租用IT资源的方式来实现业务需要,如同水力、电力资源一样,计算、存储、网">
<meta name="keywords" content="Docker,Linux,Kubernetes">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes使用指南">
<meta property="og:url" content="http://yoursite.com/2021/02/13/Kubernetes使用指南/index.html">
<meta property="og:site_name" content="Sunrise 博客">
<meta property="og:description" content="PaaS概述 PaaS(Platform as a service),平台即服务,指将软件研发的平台(或业务基础平台)作为一种服务,以SaaS的模式提交给用户.PaaS是云计算服务的其中一种模式,云计算是一种按使用量付费的模式的服务,类似一种租赁服务,服务可以是基础设施计算资源(IaaS),平台(PaaS),软件(SaaS).租用IT资源的方式来实现业务需要,如同水力、电力资源一样,计算、存储、网">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://d33wubrfki0l68.cloudfront.net/518e18713c865fe67a5f23fc64260806d72b38f5/61d75/images/docs/post-ccm-arch.png">
<meta property="og:image" content="http://yoursite.com/imgs/mm_reward_qrcode_1525013906055.png">
<meta property="og:updated_time" content="2021-12-14T09:13:14.080Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kubernetes使用指南">
<meta name="twitter:description" content="PaaS概述 PaaS(Platform as a service),平台即服务,指将软件研发的平台(或业务基础平台)作为一种服务,以SaaS的模式提交给用户.PaaS是云计算服务的其中一种模式,云计算是一种按使用量付费的模式的服务,类似一种租赁服务,服务可以是基础设施计算资源(IaaS),平台(PaaS),软件(SaaS).租用IT资源的方式来实现业务需要,如同水力、电力资源一样,计算、存储、网">
<meta name="twitter:image" content="https://d33wubrfki0l68.cloudfront.net/518e18713c865fe67a5f23fc64260806d72b38f5/61d75/images/docs/post-ccm-arch.png">

<link rel="canonical" href="http://yoursite.com/2021/02/13/Kubernetes使用指南/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Kubernetes使用指南 | Sunrise 博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Sunrise 博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/13/Kubernetes使用指南/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="yjdwbj">
      <meta itemprop="description" content="最是人间留不住,朱颜辞镜花辞树">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sunrise 博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kubernetes使用指南
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-02-13 12:44:32" itemprop="dateCreated datePublished" datetime="2021-02-13T12:44:32+08:00">2021-02-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-12-14 17:13:14" itemprop="dateModified" datetime="2021-12-14T17:13:14+08:00">2021-12-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="PaaS概述"><a href="#PaaS概述" class="headerlink" title="PaaS概述"></a><code>PaaS</code>概述</h1><ul>
<li><code>PaaS(Platform as a service)</code>,平台即服务,指将软件研发的平台(或业务基础平台)作为一种服务,以<code>SaaS</code>的模式提交给用户.<code>PaaS</code>是云计算服务的其中一种模式,云计算是一种按使用量付费的模式的服务,类似一种租赁服务,服务可以是基础设施计算资源(IaaS),平台(PaaS),软件(SaaS).租用IT资源的方式来实现业务需要,如同水力、电力资源一样,计算、存储、网络将成为企业IT运行的一种被使用的资源,无需自己建设,可按需获得.<code>PaaS</code>的实质是将互联网的资源服务化为可编程接口,为第三方开发者提供有商业价值的资源和服务平台.简而言之,<code>IaaS</code>就是卖硬件及计算资源,<code>PaaS</code>就是卖开发、运行环境,<code>SaaS</code>就是卖软件.</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th>说明</th>
<th>比喻</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">IaaS:Infrastructure-as-a-Service(基础设施即服务)</td>
<td>提供的服务是计算基础设施</td>
<td>地皮,需要自己盖房子</td>
<td>Amazon EC2(亚马逊弹性云计算),阿里云</td>
</tr>
<tr>
<td style="text-align:center">PaaS: Platform-as-a-Service(平台即服务)</td>
<td>提供的服务是软件研发的平台或业务基础平台</td>
<td>商品房,需要自己装修</td>
<td>GAE(谷歌开发者平台),heroku</td>
</tr>
<tr>
<td style="text-align:center">SaaS: Software-as-a-Service(软件即服务)</td>
<td>提供的服务是运行在云计算基础设施上的应用程序</td>
<td>酒店套房,可以直接入住</td>
<td>谷歌的 Gmail 邮箱</td>
</tr>
</tbody>
</table>
<h2 id="Kubernetes概述"><a href="#Kubernetes概述" class="headerlink" title="Kubernetes概述"></a><code>Kubernetes</code>概述</h2><ul>
<li><a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/" target="_blank" rel="noopener">What is Kubernetes?</a></li>
<li><code>Kubernetes</code>是<code>Google</code>开源的容器集群管理系统.它构建<code>Docker</code>技术之上,为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能,本质上可看作是基于容器技术的<code>Micro-PaaS</code>平台,即第三代<code>PaaS</code>的代表性项目.</li>
<li>Kubernetes架构图<br><img src="https://d33wubrfki0l68.cloudfront.net/518e18713c865fe67a5f23fc64260806d72b38f5/61d75/images/docs/post-ccm-arch.png" alt="Kubernetes"></li>
</ul>
<h3 id="Kubernetes的基本概念"><a href="#Kubernetes的基本概念" class="headerlink" title="Kubernetes的基本概念"></a><code>Kubernetes</code>的基本概念</h3><h4 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a><code>Pod</code></h4><ul>
<li><code>Pod</code>是若干个相关容器的组合,是一个逻辑概念,<code>Pod</code>包含的容器运行在同一个宿主机上,这些容器使用相同的网络命名空间,IP地址和端口,相互之间能通过<code>localhost</code>来发现和通信,共享一块存储卷空间.在<code>Kubernetes</code>中创建、调度和管理的最小单位是<code>Pod</code>.一个<code>Pod</code>一般只放一个业务容器和一个用于统一网络管理的网络容器.</li>
</ul>
<h4 id="Replication-Controller"><a href="#Replication-Controller" class="headerlink" title="Replication Controller"></a><code>Replication Controller</code></h4><ul>
<li><code>Replication Controller</code>是用来控制管理<code>Pod</code>副本(Replica,或者称实例),<code>Replication Controller</code>确保任何时候<code>Kubernetes</code>集群中有指定数量的<code>Pod</code>副本在运行,如果少于指定数量的<code>Pod</code>副本,<code>Replication Controller</code>会启动新的<code>Pod</code>副本,反之会杀死多余的以保证数量不变.另外<code>Replication Controller</code>是弹性伸缩、滚动升级的实现核心.</li>
</ul>
<h4 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a><code>Deployment</code></h4><ul>
<li><code>Deployment</code>是一种更加简单的更新<code>RC</code>和<code>Pod</code>的机制.通过在<code>Deployment</code>中描述期望的集群状态,<code>Deployment Controller</code>会将现在的集群状态在一个可控的速度下渐渐更新成期望的集群状态.<code>Deployment</code>的主要的职责同样是为了保证<code>Pod</code>的数量和健康,而且绝大多数的功能与<code>Replication Controller</code>完全一样,因些可以被看作新一代的<code>RC</code>的超集.它的特性有:事件和状态查看,回滚,版本记录,暂停和启动,多种升级方案:<code>Recreate,RollingUpdate</code>.</li>
</ul>
<h4 id="Job"><a href="#Job" class="headerlink" title="Job"></a><code>Job</code></h4><ul>
<li>从程序的运行形态上来区分,我们可以将<code>Pod</code>分成两类:长期运行服务(jboss,mysql,nginx等)和一次性任务(如并行数据计算,测试).<code>RC</code>创建的<code>Pod</code>是长时运行的服务,而<code>Job</code>创建的<code>Pod</code>的都是一次性任务.</li>
</ul>
<h4 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a><code>StatefulSet</code></h4><ul>
<li><code>StatefulSet</code>是在与有状态的应用及分布式系统一起使用的.<code>StatefulSet</code>使用起来相对复杂,当应用具有以下特点时才使用它.<ul>
<li>有唯一的稳定网络标识符需求.</li>
<li>有稳定性,持久化数据存储需求.</li>
<li>有序的部署和扩展需求.</li>
<li>有序的删除和终止需求.</li>
<li>有序的自动滚动更新需求.</li>
</ul>
</li>
</ul>
<h4 id="Service"><a href="#Service" class="headerlink" title="Service"></a><code>Service</code></h4><ul>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noopener">Kubernetes Service文档</a></li>
<li><code>Service</code>是真实应用服务的抽象,定义了<code>Pod</code>的逻辑集合和访问这个<code>Pod</code>集合的策略,<code>Service</code>将代理<code>Pod</code>对外表现为一个单一访问接口,外部不需要了解后端<code>Pod</code>如何运行,这给扩展或维护带来很大的好处,提供了一套简化的服务代理和发现机制.<code>Service</code>共有四种类型:<ul>
<li><code>ClusterIP</code>: 通过集群内部的IP地址暴露服务,此地址仅在集群内部可达,而无法被集群外部的客户端访问,此为默认的<code>Service</code>类型.</li>
<li><code>NodePort</code>: 这种类型建立在<code>ClusterIP</code>类型之止,其在每个节点上的IP地址的某静态端口(NodePort)暴露服务,因此,它依然会为<code>Service</code>分配集群IP地址,并将此作为<code>NodePort</code>的路由目标.</li>
<li><code>LoadBalancer</code>: 这种类型建构在<code>NodePort</code>类型之上,其通过<code>cloud provider</code>提供的负载均衡器将服务暴露到集群外部.因此<code>LoadBalancer</code>一样具有<code>NodePort</code>和<code>ClusterIP</code>.(目前只有云服务商才可支持,如果是用<code>VirtualBox</code>做实验,只能是<code>ClusterIP</code>或<code>NodePort</code>)</li>
<li><code>ExternalName</code>: 其通过将<code>Service</code>映射到由<code>externalName</code>字段的内容指定的主机名来暴露服务,此主机名需要被<code>DNS</code>服务解析到<code>CNAME</code>类型的记录.</li>
</ul>
</li>
</ul>
<h4 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a><code>Ingress</code></h4><ul>
<li><code>Ingrees</code>资源,它实现的是”<code>HTTP(S)负载均衡器</code>“,它是<code>k8s API</code>的标准资源类型之一,它其实就是基于DNS名称或URL路径把请求转发到指定的<code>Service</code>资源的规则,用于将集群外部的请求流量转发到集群内部完成服务发布,<code>Ingress</code>资源自身并不能进行流量穿透,它仅是一组路由规则的集合. 不同于<code>Deployment</code>控制器等,<code>Ingress</code>控制器并不直接运行为<code>kube-controller-manager</code>的一部分,它是<code>k8s</code>集群的一个重要附件,类似于<code>CoreDNS</code>,需要在集群上单独部署.</li>
</ul>
<h4 id="Label"><a href="#Label" class="headerlink" title="Label"></a><code>Label</code></h4><ul>
<li><code>Label</code>是用于区分<code>Pod、Service、Replication Controller</code>的<code>Key/Value</code>键值对,实际上<code>Kubernetes</code>中的任意<code>API</code>对象都可以通过<code>Label</code>进行标识.每个<code>API</code>对象可以有多个<code>Label</code>,但是每个<code>Label</code>的<code>Key</code>只能对应一个<code>Value</code>.<code>Label</code>是<code>Service</code>和<code>Replication Controller</code>运行的基础,它们都通过<code>Label</code>来关联<code>Pod</code>,相比于强绑定模型,这是一种非常好的松耦合关系.</li>
</ul>
<h4 id="Node"><a href="#Node" class="headerlink" title="Node"></a><code>Node</code></h4><ul>
<li><code>Kubernets</code>属于主从的分布式集群架构,<code>Kubernets Node</code>(简称为<code>Node</code>,早期版本叫做<code>Minion</code>)运行并管理容器.<code>Node</code>作为<code>Kubernetes</code>的操作单元,将用来分配给<code>Pod</code>(或者说容器)进行绑定,<code>Pod</code>最终运行在<code>Node</code>上,<code>Node</code>可以认为是<code>Pod</code>的宿主机.</li>
</ul>
<h3 id="Kubernetes架构"><a href="#Kubernetes架构" class="headerlink" title="Kubernetes架构"></a><code>Kubernetes</code>架构</h3><h4 id="Master节点"><a href="#Master节点" class="headerlink" title="Master节点"></a><code>Master</code>节点</h4><ul>
<li><code>Master</code>是<code>k8s</code>集群的大脑,运行服务有:<ul>
<li>kube-apiserver</li>
<li>kube-scheduler</li>
<li>kube-controller-manager</li>
<li>etcd,Pod 网络(如 Flannel,Canal)</li>
</ul>
</li>
</ul>
<h5 id="API-Server-kube-apiserver"><a href="#API-Server-kube-apiserver" class="headerlink" title="API Server(kube-apiserver)"></a><code>API Server(kube-apiserver)</code></h5><ul>
<li><code>Api Server</code>是<code>k8s</code>集群的前端接口,各种工具可以通过它管理<code>Cluster</code>的各种资源.</li>
</ul>
<h5 id="Scheduler-kube-scheduler"><a href="#Scheduler-kube-scheduler" class="headerlink" title="Scheduler(kube-scheduler)"></a><code>Scheduler(kube-scheduler)</code></h5><ul>
<li><code>Scheduler</code>负责决定将<code>Pod</code>放在那个<code>Node</code>上运行.它调试时会充分考虑<code>Cluster</code>的拓扑结构,找到一个最优方案.</li>
</ul>
<h5 id="Controller-Manager-kube-controller-manager"><a href="#Controller-Manager-kube-controller-manager" class="headerlink" title="Controller Manager(kube-controller-manager)"></a><code>Controller Manager(kube-controller-manager)</code></h5><ul>
<li><code>Controller Manager</code>负责管理<code>Cluster</code>各种资源.保证资源的处于预期的状态.它是由多种<code>controller</code> 组成的.</li>
</ul>
<h5 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a><code>etcd</code></h5><ul>
<li><code>etcd</code>负责保存<code>k8s</code>的配置信息和各种资源的状态信息.当数据发生变化时,<code>etcd</code>会快速地通知<code>k8s</code>相关组件.</li>
</ul>
<h5 id="Pod网络"><a href="#Pod网络" class="headerlink" title="Pod网络"></a><code>Pod</code>网络</h5><p>-<code>Pod</code>要能够相互通信,<code>k8s</code>必须部署<code>Pod</code>网络,<code>flannel</code> 是其中一个可选的方案.</p>
<h4 id="Node节点"><a href="#Node节点" class="headerlink" title="Node节点"></a><code>Node</code>节点</h4><ul>
<li><code>Node</code>是<code>Pod</code>运行的地方,<code>k8s</code> 支持<code>Docker,rkt</code>等容器的<code>Runtime</code>.它上面运行的组件有<code>kubelet,kube-proxy,Pod</code>网络.</li>
</ul>
<h5 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a><code>kubelet</code></h5><ul>
<li><code>kubelet</code>是<code>Node</code>的<code>agent</code>,当<code>Scheduler</code>确定在某个<code>Node</code>上运行<code>Pod</code>后,会将<code>Pod</code>的具体配置信息(image,volume)发给该节点的<code>kubelet</code>.<code>kubelet</code>根据这该信息创建各运行容器,并向<code>master</code>报告状态.</li>
</ul>
<h5 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a><code>kube-proxy</code></h5><ul>
<li><code>service</code>在逻辑上代表了后端的多个<code>Pod</code>,外界通过<code>service</code>访问<code>Pod</code>.service 接收到的请求是如何转发到相应的<code>Pod</code>.如有多个副本,<code>kube-proxy</code>会实现负载均衡.</li>
</ul>
<h5 id="Secret-amp-ConfigMap"><a href="#Secret-amp-ConfigMap" class="headerlink" title="Secret &amp; ConfigMap"></a><code>Secret &amp; ConfigMap</code></h5><ul>
<li><code>Secret</code>可以为<code>Pod</code>提供密码,<code>Token</code>,私钥等敏感数据;对于一些非敏感的数据,比如应用的配置信息,可以使用<code>ConfigMap</code>.</li>
</ul>
<h4 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h4><h5 id="网络相关"><a href="#网络相关" class="headerlink" title="网络相关"></a>网络相关</h5><ul>
<li><strong>ACI</strong> provides integrated container networking and network security with Cisco ACI.</li>
<li><strong>Calico</strong> is a secure L3 networking and network policy provider.</li>
<li><strong>Canal</strong> unites Flannel and Calico, providing networking and network policy.</li>
<li><strong>Cilium</strong> is a L3 network and network policy plugin that can enforce HTTP/API/L7 policies transparently. Both routing and overlay/encapsulation mode are supported.</li>
<li><strong>CNI-Genie</strong> enables Kubernetes to seamlessly connect to a choice of CNI plugins, such as Calico, Canal, Flannel, Romana, or Weave.</li>
<li><strong>Contiv</strong> provides configurable networking (native L3 using BGP, overlay using vxlan, classic L2, and Cisco-SDN/ACI) for various use cases and a rich policy framework.  Contiv project is fully open sourced. The installer provides both kubeadm and non-kubeadm based installation options.</li>
<li><strong>Contrail</strong>, based on Tungsten Fabric, is a open source, multi-cloud network virtualization and policy management platform. Contrail and Tungsten Fabric are integrated with  orchestration systems such as Kubernetes, OpenShift, OpenStack and Mesos, and provide isolation modes for virtual machines, containers/pods and bare metal workloads.</li>
<li><strong>Flannel</strong> is an overlay network provider that can be used with Kubernetes.</li>
<li><strong>Knitter</strong> is a network solution supporting multiple networking in Kubernetes.</li>
<li><strong>Multus</strong> is a Multi plugin for multiple network support in Kubernetes to support all CNI plugins (e.g. Calico, Cilium, Contiv, Flannel), in addition to SRIOV, DPDK, OVS-DPDK and VPP based workloads in Kubernetes.</li>
<li><strong>NSX-T</strong> Container Plug-in (NCP) provides integration between VMware NSX-T and container orchestrators such as Kubernetes, as well as integration between NSX-T and \     container-based CaaS/PaaS platforms such as Pivotal Container Service (PKS) and OpenShift.</li>
<li><strong>Nuage</strong> is an SDN platform that provides policy-based networking between Kubernetes Pods and non-Kubernetes environments with visibility and security monitoring.</li>
<li><strong>Romana</strong> is a Layer 3 networking solution for<code>Pod</code>networks that also supports the NetworkPolicy API. Kubeadm add-on installation details available here.</li>
<li><strong>Weave Net</strong> provides networking and network policy, will carry on working on both sides of a network partition, and does not require an external database.</li>
</ul>
<h5 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h5><ul>
<li><strong>CoreDNS</strong> is a flexible, extensible DNS server which can be installed as the in-cluster DNS for pods.</li>
</ul>
<h5 id="可视化面板"><a href="#可视化面板" class="headerlink" title="可视化面板"></a>可视化面板</h5><ul>
<li><strong>Dashboard</strong> is a dashboard web interface for Kubernetes.</li>
<li><strong>Weave Scope</strong> is a tool for graphically visualizing your containers, pods, services etc. Use it in conjunction with a Weave Cloud account or host the UI yourself.</li>
</ul>
<h2 id="安装Minikube"><a href="#安装Minikube" class="headerlink" title="安装Minikube"></a>安装<code>Minikube</code></h2><ul>
<li>链接:<ul>
<li><a href="https://github.com/kubernetes/minikube" target="_blank" rel="noopener">Github - minikube</a></li>
<li><a href="https://github.com/kubernetes/kubectl" target="_blank" rel="noopener">Github - kubectl</a></li>
<li><a href="https://kubernetes.io/docs/setup/minikube/" target="_blank" rel="noopener">Running Kubernetes Locally via Minikube</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">Creating a single master cluster with kubeadm</a></li>
<li><a href="https://jimmysong.io/kubernetes-handbook/" target="_blank" rel="noopener">Kubernetes 中文指南/云原生应用架构实践手册</a></li>
<li><a href="https://kubevirt.io/2018/Hello-KubeVirt-on-Minikube.html" target="_blank" rel="noopener">Hello Kubevirt On Minikube</a></li>
<li><a href="https://computingforgeeks.com/how-to-run-minikube-on-kvm/" target="_blank" rel="noopener">How to run Minikube on KVM</a></li>
<li><a href="https://medium.com/linagora-engineering/install-k8s-minikube-on-top-of-kvm-on-debian-9-9cd5b646063c" target="_blank" rel="noopener">Install k8s Minikube on top of KVM on Debian 9</a></li>
<li><a href="https://docs.okd.io/latest/install_config/storage_examples/shared_storage.html" target="_blank" rel="noopener">Sharing an NFS Persistent Volume (PV) Across Two Pods</a></li>
</ul>
</li>
</ul>
<ul>
<li>使用<code>Minikube</code> 是运行 <code>Kubernetes</code> 集群最简单,最快捷的途路径.<code>Minikube</code>是一个构建单节点集群的工具,对于测试<code>Kubernetes</code>和本地开发应用都非常有用,这里在<code>Debian</code>下安装,它默认会要使用到<code>VirtualBox</code>虚拟机为驱动,也可以安装<code>kvm2</code>为驱动.<code>Minikube</code>的参考文档<a href="https://docs.docker.com/machine/" target="_blank" rel="noopener">docker-machine</a>的参数.</li>
<li>第一次使用<code>minikube start</code>,它会在创建一个<code>~/.minikube</code>目录,会下载<a href="https://storage.googleapis.com/minikube/iso/minikube-v0.35.0.iso" target="_blank" rel="noopener">minikube-vxxx.iso</a>到<code>~/.minikube/cache/</code>下面,如果下载十分缓慢,可以手动<code>https://storage.googleapis.com/minikube/iso/minikube-v0.35.0.iso</code>下载复制到目录下.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">~$ curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.35.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo cp minikube /usr/<span class="built_in">local</span>/bin/ &amp;&amp; rm minikube</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以从这里https://storage.googleapis.com/minikube/releases/v0.35.0/minikube-linux-amd64下载.</span></span><br><span class="line"><span class="comment"># 下载kvm2驱动</span></span><br><span class="line">~$ wget https://github.com/kubernetes/minikube/releases/download/v0.35.0/docker-machine-driver-kvm2</span><br><span class="line">~$ chmod +x docker-machine-driver-kvm2 &amp;&amp; mv docker-machine-driver-kvm2 /usr/<span class="built_in">local</span>/bin &amp;&amp; rm minikube</span><br></pre></td></tr></table></figure>
<ul>
<li>启动一个<code>Minikube</code>虚拟机,如果直接<code>minikube start</code>就会默认使用<code>VirtualBox</code>启动.网络部分使用<code>default</code>.<code>--kvm-network</code>的参数,来源于<code>virsh net-list</code>.<code>minikube-net</code>是一个隔离的网络,也不是说不能联网的,如果需要连网,要与本机的网卡或者网络做桥接或<code>NAT</code>.</li>
<li><p><code>k8s.gcr.io</code>在国内是无法直接访问的,所以会造成<code>minikube</code>无法拖取相关的镜像,最终导致<code>minikube</code>无法正常使用.在此有几个方法可以变通一下,最简单的方法是使用代理:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--docker-env HTTP_PROXY=&lt;ip:port&gt; --docker-env HTTPS_PROXY=&lt;ip:port&gt; --docker-env NO_PROXY=127.0.0.1,localhost`</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果服务器可以访问外网,则可在<code>docker daemon</code>的启动参数(<code>/etc/sysconfig/docker</code>)中<code>OPTIONS</code><br>加上<code>--insecure-registry k8s.gcr.io</code></p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">~$  minikube start --vm-driver=kvm2 --kvm-network minikube-net --registry-mirror=https://registry.docker-cn.com --kubernetes-version v1.14.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从阿里下载过来,最好是可以使用代理直接从k8s.gcr.io下载.</span></span><br><span class="line">~$ docker pull  registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.14.0</span><br><span class="line">~$ docker pull  registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0</span><br><span class="line">~$ docker pull  registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.14.0</span><br><span class="line">~$ docker pull  registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.14.0</span><br><span class="line">~$ docker pull  registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1</span><br><span class="line">~$ docker pull  registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10</span><br><span class="line">~$ docker pull  registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用脚本批量把它们换tag,也可以把它推送到自己公司的私有仓库中去,测试使用重写TAG的方法好像不行,还是要用代理才能正常下载.</span></span><br><span class="line">~$ docker images | grep <span class="string">"aliyuncs.com"</span> | awk <span class="string">'&#123;split($1,a,"/"); print "docker tag " $1":"$2 " k8s.gcr.io/"a[3]":"$2&#125;'</span></span><br><span class="line">~$ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0 k8s.gcr.io/kube-proxy:v1.14.0</span><br><span class="line">~$ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.14.0 k8s.gcr.io/kube-apiserver:v1.14.0</span><br><span class="line">~$ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.14.0 k8s.gcr.io/kube-scheduler:v1.14.0</span><br><span class="line">~$ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.14.0 k8s.gcr.io/kube-controller-manager:v1.14.0</span><br><span class="line">~$ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1</span><br><span class="line">~$ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10</span><br><span class="line">~$ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再用手动初始化这些image到容器</span></span><br><span class="line">~$ sudo kubeadm init --kubernetes-version=v1.14.0</span><br></pre></td></tr></table></figure>
<ul>
<li><p>经过测试直接使用<code>kubeadm</code>也可以直接拉取其它的国内镜像进行安装,使用代理也可以安装,考虑到找到一个稳定可靠的代理还是有一些难度.因为<code>minikube start --vm-driver=kvm2</code>是直接在创建一个虚拟机,并通过<code>sudo kubeadm config images pull --config /var/lib/kubeadm.yaml</code>在虚拟机拉取相应的<code>docker</code>镜像组件到本地部署各种<code>k8s</code>的服务.它默认是使用<code>https://k8s.gcr.io/v2/</code>这域名去拉取镜像,</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ minikube start --vm-driver=kvm2 --kvm-network minikube-net --registry-mirror=https://registry.docker-cn.com</span><br></pre></td></tr></table></figure>
</li>
<li><p>发现参数<code>--registry-mirror</code>并没有起作用,还是会报错如下:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> Unable to pull images, <span class="built_in">which</span> may be OK: running cmd: sudo kubeadm config images pull --config /var/lib/kubeadm.yaml: <span class="built_in">command</span> failed: sudo kubeadm config images pull --config /var/lib/kubeadm.yaml</span><br><span class="line">stdout:</span><br><span class="line">stderr: failed to pull image <span class="string">"k8s.gcr.io/kube-apiserver:v1.14.0"</span>: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载<code>kubectl</code>到本地开发机器(控制端)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">~$ curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl</span><br><span class="line">~$ chmod +x kubectl &amp;&amp; sudo mv kubectl /usr/<span class="built_in">local</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入自动补全功能</span></span><br><span class="line">~$ <span class="built_in">echo</span> <span class="string">"source &lt;(kubectl completion bash)"</span> &gt;&gt; ~/.bashrc</span><br><span class="line">~$ kubectl get nodes</span><br><span class="line">NAME       STATUS   ROLES    AGE   VERSION</span><br><span class="line">minikube   Ready    &lt;none&gt;   94m   v1.13.4</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="源码编译Minikube"><a href="#源码编译Minikube" class="headerlink" title="源码编译Minikube"></a>源码编译<code>Minikube</code></h1><ul>
<li><p>下载最新GO语言编译器</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ wget -c https://golang.google.cn/doc/install?download=go1.12.4.linux-amd64.tar.gz</span><br><span class="line">~$ sudo tar xvf go1.12.4.linux-amd64.tar.gz -C /opt/</span><br><span class="line">~$ <span class="built_in">export</span> PATH=/opt/go/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>下载源码,要先创建<code>/opt/go/src/k8s.io</code>目录,在该目录下克隆代码.并且修改镜像地址</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo mkdir /opt/go/src/k8s.io &amp;&amp; <span class="built_in">cd</span> /opt/go/src/k8s.io &amp;&amp;   git <span class="built_in">clone</span> https://github.com/kubernetes/minikube.git</span><br><span class="line">~$ <span class="built_in">cd</span> minikube &amp;&amp; <span class="keyword">for</span> item <span class="keyword">in</span> `grep  -l <span class="string">"k8s.gcr.io"</span> -r *`;<span class="keyword">do</span> sed -i <span class="string">"s#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com/google_containers#g"</span> <span class="variable">$item</span>  ;<span class="keyword">done</span></span><br><span class="line">~$ make</span><br><span class="line">~$ sudo cp out/minikube-linux-amd64 /usr/<span class="built_in">local</span>/bin/minikube</span><br></pre></td></tr></table></figure>
</li>
<li><p>综上所述,因为使用<code>docker tag</code>还是有问题,源码构建的<code>Minikube</code>可以完美解决墙的问题,如果去网上下载第三方的<code>Minikube</code>二进制怕有夹带私货的问题.</p>
</li>
</ul>
<h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">⌛  Waiting <span class="keyword">for</span> pods: apiserver proxy💣  Error restarting cluster: <span class="built_in">wait</span>: waiting <span class="keyword">for</span> k8s-app=kube-proxy: timed out waiting <span class="keyword">for</span> the condition</span><br><span class="line"></span><br><span class="line">😿  Sorry that minikube crashed. If this was unexpected, we would love to hear from you:</span><br><span class="line">👉  https://github.com/kubernetes/minikube/issues/new</span><br></pre></td></tr></table></figure>
<h1 id="手动布署安装Kubernetes组件"><a href="#手动布署安装Kubernetes组件" class="headerlink" title="手动布署安装Kubernetes组件"></a>手动布署安装<code>Kubernetes</code>组件</h1><ul>
<li>Links:<ul>
<li><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" target="_blank" rel="noopener">Installing kubeadm</a></li>
<li><a href="https://yq.aliyun.com/teams/11/type_blog-cid_200-page_1" target="_blank" rel="noopener">阿里云–容器服务 Docker&amp;Kubernetes 容器服务 Docker&amp;Kubernetes</a></li>
<li><a href="https://ieevee.com/tech/2018/09/01/kubeadm.html" target="_blank" rel="noopener">墙内安装 kubernetes 教程</a></li>
<li><a href="http://mirrors.ustc.edu.cn/" target="_blank" rel="noopener">中国科学技术大学开源软件镜像</a></li>
</ul>
</li>
</ul>
<h2 id="Debian-Ubuntu发行版安装kubeadm"><a href="#Debian-Ubuntu发行版安装kubeadm" class="headerlink" title="Debian,Ubuntu发行版安装kubeadm"></a><code>Debian,Ubuntu</code>发行版安装<code>kubeadm</code></h2><ul>
<li>kubeadm: the command to bootstrap the cluster.</li>
<li>kubelet: the component that runs on all of the machines in your cluster and does things like starting pods and containers.</li>
<li>kubectl: the command line util to talk to your cluster.</li>
<li>中文<ul>
<li><code>kubeadm</code>: 用来初始化集群的指令.</li>
<li><code>kubelet</code>: 在集群中的每个节点上用来启动<code>Pod</code>和<code>container</code>等.</li>
<li><code>kubectl</code>: 用来与集群通信的命令行工具.</li>
</ul>
</li>
<li>这三个组件的安装时候要注意它们之间的版本兼容性问题.</li>
</ul>
<h3 id="官方软件仓库-在国内不能使用"><a href="#官方软件仓库-在国内不能使用" class="headerlink" title="官方软件仓库,在国内不能使用"></a>官方软件仓库,在国内不能使用</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">~$ apt-get update &amp;&amp; apt-get install -y apt-transport-https curl dirmngr</span><br><span class="line">~$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line"><span class="comment"># 或者用如下的方式安装公钥,需要依赖安装dirmngr</span></span><br><span class="line">~$ sudo apt-key  adv --keyserver  keyserver.ubuntu.com --recv-keys  6A030B21BA07F4FB</span><br><span class="line">~$ sudo bash -c <span class="string">"cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span></span><br><span class="line"><span class="string">    deb https://apt.kubernetes.io/ kubernetes-xenial main</span></span><br><span class="line"><span class="string">    EOF"</span></span><br><span class="line"><span class="comment"># 经测试 apt.kubernetes.io 重定向到k8s.io不能访问,可以使用国内镜像 http://mirrors.ustc.edu.cn/kubernetes/</span></span><br><span class="line">~$ apt-get update</span><br><span class="line">~$ apt-get install -y kubelet kubeadm kubectl</span><br><span class="line">~$ apt-mark hold kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure>
<h3 id="阿里云镜像仓库"><a href="#阿里云镜像仓库" class="headerlink" title="阿里云镜像仓库"></a>阿里云镜像仓库</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">~$ apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line">~$ curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">~$ sudo bash -c <span class="string">"cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span></span><br><span class="line"><span class="string">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span></span><br><span class="line"><span class="string">EOF"</span></span><br><span class="line">~$ sudo apt-get update &amp;&amp; sudo apt-get install kubelet kubeadm kubectl -y</span><br><span class="line">~$ sudo apt-mark hold kubelet kubeadm kubectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接使用curl下载二进制 ,要用代理.</span></span><br><span class="line">~$ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl</span><br></pre></td></tr></table></figure>
<ul>
<li>查询当前版本需要那些<code>docker image</code>.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">~$ kubeadm config images list --kubernetes-version v1.14.0</span><br><span class="line">k8s.gcr.io/kube-apiserver:v1.14.0</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.14.0</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.14.0</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.14.0</span><br><span class="line">k8s.gcr.io/pause:3.1</span><br><span class="line">k8s.gcr.io/etcd:3.3.10</span><br><span class="line">k8s.gcr.io/coredns:1.3.1</span><br></pre></td></tr></table></figure>
<h3 id="安装Master节点"><a href="#安装Master节点" class="headerlink" title="安装Master节点"></a>安装<code>Master</code>节点</h3><h4 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h4><ul>
<li>目前<code>Kubernetes</code>支持多种网络方案,如: <code>Flannel,Canal,Weave Net,Calico</code>等.它都是实现了<code>CNI</code>的规范.<br>下面以安装<a href="https://docs.projectcalico.org/v3.6/getting-started/kubernetes/" target="_blank" rel="noopener"><code>Canal</code></a>为示例.其它各安装<a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">参考这里的 Installing a<code>Pod</code>network add-on 部分</a>,<a href="https://kubernetes.io/zh/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">中文文档</a>,在<code>kubeadm init</code>是必须要指定一个网络,不然会出现其它问题.根据上述链接指导如:<ul>
<li><code>Calico 网络模型</code>:<code>kubeadm init --pod-network-cidr=192.168.0.0/16</code>,它只工在<code>amd64</code>,<code>arm64</code>,<code>ppc64le</code>三个平台.</li>
<li><code>Flannel 网络模型</code>:<code>kubeadm init --pod-network-cidr=10.244.0.0/16</code>,并修改内核参数<br><code>sysctl net.bridge.bridge-nf-call-iptables=1</code>,工作在Linux的<code>amd64,arm,arm64,ppc64le,s390x</code></li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl apply -f \</span><br><span class="line">https://docs.projectcalico.org/v3.6/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br><span class="line">configmap/calico-config created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created</span><br><span class="line">[...]</span><br><span class="line">serviceaccount/calico-kube-controllers created</span><br></pre></td></tr></table></figure>
<ul>
<li>安装<code>Master</code>节点,注意在国内必须指定<code>--image-repository</code>,默认的<code>k8s.gcr.io</code>是不能直接访问的,还有<code>--kubernetes-version</code>必须与<code>kubelet</code>的组件版本匹配.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers  --kubernetes-version v1.14.0 --pod-network-cidr=10.244.0.0/16</span><br><span class="line">[init] Using Kubernetes version: v1.14.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">	[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">'kubeadm config images pull'</span></span><br><span class="line">[...]</span><br><span class="line"><span class="comment"># 安装成功后,注意下面提示的操作项流程依次进行.</span></span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a`Pod`network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 172.18.127.186:6443 --token z8r97j.3ovdfddb6df9lnq7 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:07767a67fa6c38feda7471ee5e1a15a0a9c417cfdf6cf457ff577297f22d9415</span><br></pre></td></tr></table></figure>
<ul>
<li><p>根据<code>kubeadm init</code>的参数,安装<code>Flannel网络插件</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/flannel created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/flannel created</span><br><span class="line">serviceaccount/flannel created</span><br><span class="line">configmap/kube-flannel-cfg created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-amd64 created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-arm64 created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-arm created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-ppc64le created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-s390x created</span><br></pre></td></tr></table></figure>
</li>
<li><p>按照上述安装成功后的提示,配置<code>Master</code>节点信息.并安装网络插件请<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" target="_blank" rel="noopener">参考这里</a>.</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">~$ mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">~$ sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">~$ sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看token</span></span><br><span class="line">~$ kubeadm token list</span><br><span class="line">TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPS</span><br><span class="line">5smm64.9zpyhaqxghohh6b2   23h       2019-04-20T14:45:14+08:00   authentication,signing   The default bootstrap token generated by <span class="string">'kubeadm init'</span>.   system:bootstrappers:kubeadm:default-node-token</span><br></pre></td></tr></table></figure>
<h4 id="修改Kubelet的启动参数"><a href="#修改Kubelet的启动参数" class="headerlink" title="修改Kubelet的启动参数"></a>修改<code>Kubelet</code>的启动参数</h4><ul>
<li><code>kubelet</code>组件是通过<code>systemctl</code>来管理的,因此可以在每个节点里的<code>/etc/systemed/system</code>找到它的配置文件.<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">~<span class="comment"># cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span></span><br><span class="line"><span class="comment"># Note: This dropin only works with kubeadm and kubelet v1.11+</span></span><br><span class="line">[Service]</span><br><span class="line">Environment=<span class="string">"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"</span></span><br><span class="line">Environment=<span class="string">"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"</span></span><br><span class="line"><span class="comment"># This is a file that "kubeadm init" and "kubeadm join" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically</span></span><br><span class="line">EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"><span class="comment"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use</span></span><br><span class="line"><span class="comment"># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.</span></span><br><span class="line">EnvironmentFile=-/etc/default/kubelet</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/kubelet <span class="variable">$KUBELET_KUBECONFIG_ARGS</span> <span class="variable">$KUBELET_CONFIG_ARGS</span> <span class="variable">$KUBELET_KUBEADM_ARGS</span> <span class="variable">$KUBELET_EXTRA_ARGS</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="安装集群节点"><a href="#安装集群节点" class="headerlink" title="安装集群节点"></a>安装集群节点</h3><ul>
<li><p>在另一个机器里安装上述的三个组件,就可以运行下面命令加入<code>k8s</code>集群管理了.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo kubeadm join 172.18.127.186:6443 --token z8r97j.3ovdfddb6df9lnq7     --discovery-token-ca-cert-hash sha256:07767a67fa6c38feda7471ee5e1a15a0a9c417cfdf6cf457ff577297f22d9415</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">	[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with <span class="string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span></span><br><span class="line">[kubelet-start] Downloading configuration <span class="keyword">for</span> the kubelet from the <span class="string">"kubelet-config-1.14"</span> ConfigMap <span class="keyword">in</span> the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[kubelet-start] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 Master 节点上查看集群节点数.</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl  get node</span><br><span class="line">NAME             STATUS   ROLES    AGE    VERSION</span><br><span class="line">aliyun-machine   Ready    master   110m   v1.14.0</span><br><span class="line">dig001           Ready    &lt;none&gt;   84m    v1.14.0</span><br><span class="line">fe001            Ready    &lt;none&gt;   2m8s   v1.14.0</span><br></pre></td></tr></table></figure>
<ul>
<li>查看集群的要完整架构,Master 上也可以运行应用,即 Master 同时也是一个 Node.<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get pod --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   coredns-d5947d4b-sr5zt               1/1     Running   0          6m3s    10.244.0.6       k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-d5947d4b-tznh2               1/1     Running   0          6m3s    10.244.0.5       k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running   0          5m11s   172.18.127.186   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running   0          5m15s   172.18.127.186   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running   0          5m13s   172.18.127.186   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-9d965          1/1     Running   0          5m17s   172.18.127.186   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-c8dkh          1/1     Running   0          38s     172.18.192.76    dig001       &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-kswj2          1/1     Running   0          52s     172.18.253.222   fe001        &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-5g9vp                     1/1     Running   0          38s     172.18.192.76    dig001       &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-cqzfl                     1/1     Running   0          52s     172.18.253.222   fe001        &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-pjbbg                     1/1     Running   0          6m3s    172.18.127.186   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running   0          5m19s   172.18.127.186   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>获取Pod的完整信息<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get pod &lt;podname&gt; --output json   <span class="comment"># 用JSON格式显示Pod的完整信息</span></span><br><span class="line">~$ kubectl get pod &lt;podname&gt; --output yaml   <span class="comment"># 用YAML格式显示Pod的完整信息</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="拆除k8s集群"><a href="#拆除k8s集群" class="headerlink" title="拆除k8s集群"></a>拆除<code>k8s</code>集群</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl drain &lt;node name&gt; --delete-local-data --force --ignore-daemonsets</span><br><span class="line">~$ kubectl delete node &lt;node name&gt;</span><br><span class="line">~$ kubeadm reset</span><br></pre></td></tr></table></figure>
<h1 id="安装HelloWorld共享Pod数据"><a href="#安装HelloWorld共享Pod数据" class="headerlink" title="安装HelloWorld共享Pod数据"></a>安装<code>HelloWorld</code>共享<code>Pod</code>数据</h1><ul>
<li><a href="https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/" target="_blank" rel="noopener">Communicate Between Containers in the Same Pod Using a Shared Volume</a></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span> <span class="comment">#  for k8s versions before 1.9.0 use apps/v1beta2  and before 1.8.0 use extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">write</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">debian:latest</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["bash","-c","echo</span> <span class="string">\"Hello</span> <span class="string">World\"</span> <span class="string">&gt;&gt;</span> <span class="string">/data/hello"]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">read</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">debian:latest</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["bash","-c","sleep</span> <span class="number">10</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/data/hello"]</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/tmp</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl apply -f hello-world.yaml</span><br></pre></td></tr></table></figure>
<h2 id="通过Github安装Kubernetes"><a href="#通过Github安装Kubernetes" class="headerlink" title="通过Github安装Kubernetes"></a>通过<code>Github</code>安装<code>Kubernetes</code></h2><h3 id="Etcd"><a href="#Etcd" class="headerlink" title="Etcd"></a><code>Etcd</code></h3><ul>
<li><a href="https://github.com/etcd-io/etcd" target="_blank" rel="noopener">CoreOS Etcd</a></li>
<li>从<a href="https://github.com/etcd-io/etcd/releases/download/v3.3.12/etcd-v3.3.12-linux-amd64.tar.gz" target="_blank" rel="noopener">Github 下载</a></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ wget -c https://github.com/etcd-io/etcd/releases/download/v3.3.12/etcd-v3.3.12-linux-amd64.tar.gz</span><br><span class="line">~$ tar zxvf etcd-v3.3.12-linux-amd64.tar.gz</span><br><span class="line">~$ <span class="built_in">cd</span> etcd-v3.3.12-linux-amd64 &amp;&amp; sudo cp &#123;etcd,etcdctl&#125; /usr/<span class="built_in">local</span>/bin</span><br></pre></td></tr></table></figure>
<ul>
<li><p>运行<code>Etcd</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ etcd -name etcd --data-dir /var/lib/etcd -listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \</span><br><span class="line">-advertise-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 &gt;&gt; /var/<span class="built_in">log</span>/etcd.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询它的建康状态</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ etcdctl  -C http://127.0.0.1:4001 cluster-healthmember 8e9e05c52164694d is healthy: got healthy result from http://0.0.0.0:2379</span><br><span class="line">cluster is healthy</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Kubernetes发布包安装"><a href="#Kubernetes发布包安装" class="headerlink" title="Kubernetes发布包安装"></a><code>Kubernetes</code>发布包安装</h3><ul>
<li><a href="https://github.com/kubernetes/kubernetes/" target="_blank" rel="noopener">Kubernetes</a></li>
<li><p>通过<a href="https://github.com/kubernetes/kubernetes/releases/download/v1.14.0/kubernetes.tar.gz" target="_blank" rel="noopener">github 下载</a>最新的版本.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">~$ wget -c https://github.com/kubernetes/kubernetes/releases/download/v1.14.0/kubernetes.tar.gz</span><br><span class="line">~$ tar xvf kubernetes.tar.gz &amp;&amp; <span class="built_in">cd</span> kubernetes</span><br><span class="line">~$ tree -L 1</span><br><span class="line">.</span><br><span class="line">├── client</span><br><span class="line">├── cluster</span><br><span class="line">├── docs</span><br><span class="line">├── hack</span><br><span class="line">├── LICENSES</span><br><span class="line">├── README.md</span><br><span class="line">├── server</span><br><span class="line">└── version</span><br><span class="line"></span><br><span class="line">$ cat server/README</span><br><span class="line">Server binary tarballs are no longer included <span class="keyword">in</span> the Kubernetes final tarball.</span><br><span class="line"></span><br><span class="line">Run cluster/get-kube-binaries.sh to download client and server binaries.</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据上面的<code>README</code>提示,服务端的组件没有包含在上面的压缩包,而是要通过运行<code>cluster/get-kube-binaries.sh</code>从<code>https://dl.k8s.io/v1.14.0</code>下载.但是<code>dl.k8s.io</code>在国内是不能直接访问的.</p>
</li>
</ul>
<h1 id="安装Minio服务-单节点服务"><a href="#安装Minio服务-单节点服务" class="headerlink" title="安装Minio服务(单节点服务)"></a>安装<code>Minio</code>服务(单节点服务)</h1><ul>
<li>链接:<ul>
<li><a href="https://github.com/minio/minio" target="_blank" rel="noopener">Github MinIO</a></li>
<li><a href="https://docs.min.io/cn/" target="_blank" rel="noopener">MinIO Quickstart Guide文档</a></li>
<li><a href="https://github.com/kubernetes/examples/tree/master/staging/storage/minio" target="_blank" rel="noopener">Cloud Native Deployment of Minio using Kubernetes</a></li>
<li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/" target="_blank" rel="noopener">Configure a Pod to Use a PersistentVolume for Storage</a></li>
<li><a href="https://docs.min.io/cn/deploy-minio-on-kubernetes.html" target="_blank" rel="noopener">MinIO中文手册</a></li>
</ul>
</li>
<li><code>MinIO</code>是一个高性能的<code>Kubernetes</code>下原生的对像存储,它的<code>API</code>同样兼容<code>Amazon S3</code>云存储服务.下面使用<code>kubectl</code>直接按装<code>Minio</code>是参照<a href="https://docs.min.io/docs/deploy-minio-on-kubernetes.html" target="_blank" rel="noopener"><code>Deploy MinIO on Kubernetes</code></a>,下面也可以使用<code>Helm</code>安装它.</li>
<li><p>快速运行单节点服务, 下面运行成功,后可以打开<code>http://127.0.0.1:9000</code>,使用<code>minioadmin:minioadmin</code>登录到控制台.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ podman run -p 9000:9000 -p 9001:9001 \</span><br><span class="line">  quay.io/minio/minio server /data --console-address <span class="string">":9001"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>或者绑定一个本机目录<code>minio_data</code>到容器内去.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ podman run -v `<span class="built_in">pwd</span>`/minio_data:/data -p 9000:9000 -p 9001:9001 \</span><br><span class="line">  quay.io/minio/minio server /data --console-address <span class="string">":9001"</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="MinIO服务端"><a href="#MinIO服务端" class="headerlink" title="MinIO服务端"></a><code>MinIO</code>服务端</h2><h3 id="创建PV-Persistent-Volume"><a href="#创建PV-Persistent-Volume" class="headerlink" title="创建PV (Persistent Volume)"></a>创建<code>PV (Persistent Volume)</code></h3><ul>
<li>在<code>Kubernetes</code>环境中,可以使用<a href="https://github.com/minio/operator" target="_blank" rel="noopener">MinIO Kubernetes Operator</a></li>
<li>下面是一个资源描述文件,创建一个10G大小的,本地类型的<code>PV</code>. <code>PV</code>可以理解成<code>k8s</code>集群中的某个网络存储中对应的一块存储,它与<code>Voleme</code>很类似.<code>PV</code>只能是网络存储,不属于任何的<code>Node</code>,但可以在每个<code>Node</code>上访问它.<code>PV</code>并不是定义在<code>Pod</code>上的,而是独立于<code>Pod</code>之外的定义.<code>PV</code>目前支持的类型包括:<ul>
<li>GCEPersistentDisk,</li>
<li>AWSElasticBlockStore,</li>
<li>AzureFile,FC(Fibre Channel),</li>
<li>NFS,</li>
<li>iSCSI,</li>
<li>RBD(Rados Block Device),</li>
<li>CephFS,</li>
<li>GlusterFS,</li>
<li>HostPath(仅供单机测试)等等.</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">~$ cat pv.yaml</span><br><span class="line"></span><br><span class="line">kind: PersistentVolume</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: task-pv-volume</span><br><span class="line">  labels:</span><br><span class="line">    <span class="built_in">type</span>: <span class="built_in">local</span></span><br><span class="line">spec:</span><br><span class="line">  storageClassName: standard</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 10Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  hostPath:</span><br><span class="line">    path: <span class="string">"/tmp/data"</span></span><br><span class="line"></span><br><span class="line">~$ kubectl create -f pv.yaml</span><br></pre></td></tr></table></figure>
<h3 id="安装Minio-PVC-Persistent-Volume-Claim"><a href="#安装Minio-PVC-Persistent-Volume-Claim" class="headerlink" title="安装Minio PVC (Persistent Volume Claim)"></a>安装<code>Minio PVC (Persistent Volume Claim)</code></h3><ul>
<li><code>PVC</code>指定所需要的存储大小,然后<code>k8s</code>会选择满足条件的PV进行绑定,如果<code>PVC</code>创建之后没绑定到PV,就会出现<code>Pending</code>的错误,所以要按照<code>PV-&gt;PVC-&gt;Deployment-&gt;Service</code>这个顺序来试验.<code>PVC</code>的几种状态有:<ul>
<li>Available: 空闲状态</li>
<li>Bound: 已经绑定到某个PVC上.</li>
<li>Released: 对应的PVC已经删除,但资源还没有被集群收回.</li>
<li>Failed: PV 自动回收失败.</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-pvc.yaml?raw=<span class="literal">true</span></span><br><span class="line">persistentvolumeclaim/minio-pv-claim created</span><br></pre></td></tr></table></figure>
<ul>
<li><p>也可以把上面这个链接的文件下载到本地,修改</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">~$ cat minio-pvc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  <span class="comment"># This name uniquely identifies the PVC. This is used in deployment.</span></span><br><span class="line">  name: minio-pv-claim</span><br><span class="line">spec:</span><br><span class="line">  <span class="comment"># Read more about access modes here: http://kubernetes.io/docs/user-guide/persistent-volumes/#access-modes</span></span><br><span class="line">  storageClassName: standard</span><br><span class="line">  accessModes:</span><br><span class="line">    <span class="comment"># The volume is mounted as read-write by a single node</span></span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    <span class="comment"># This is the request for storage. Should be available in the cluster.</span></span><br><span class="line">    requests:</span><br><span class="line">      storage: 10Gi</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看系统中的<code>PVC</code>状态,下面显示状态是<code>Pending</code>,使用<code>describe</code>查看它的详情.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get pvc  --namespace default</span><br><span class="line">NAME             STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">minio-pv-claim   Pending</span><br><span class="line">~$ kubectl get pvc  --namespace default</span><br><span class="line">NAME             STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">minio-pv-claim   Pending                                                     2m22s</span><br><span class="line">lcy@k8s-master:~$ kubectl describe pvc minio-pv-claim</span><br><span class="line">Name:          minio-pv-claim</span><br><span class="line">Namespace:     default</span><br><span class="line">StorageClass:</span><br><span class="line">Status:        Pending</span><br><span class="line">Volume:</span><br><span class="line">Labels:        &lt;none&gt;</span><br><span class="line">Annotations:   &lt;none&gt;</span><br><span class="line">Finalizers:    [kubernetes.io/pvc-protection]</span><br><span class="line">Capacity:</span><br><span class="line">Access Modes:</span><br><span class="line">VolumeMode:    Filesystem</span><br><span class="line">Events:</span><br><span class="line">  Type       Reason         Age                 From                         Message</span><br><span class="line">  ----       ------         ----                ----                         -------</span><br><span class="line">  Normal     FailedBinding  4s (x14 over 3m2s)  persistentvolume-controller  no persistent volumes available <span class="keyword">for</span> this claim and no storage class is <span class="built_in">set</span></span><br><span class="line">Mounted By:  minio-6d4d48db87-wxr4d</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据上面<code>Events</code>显示错误如下:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FailedBinding  4s (x14 over 3m2s)  persistentvolume-controller  no persistent volumes available <span class="keyword">for</span> this claim and no storage class is <span class="built_in">set</span>`</span><br></pre></td></tr></table></figure>
</li>
<li><p>这就是它为什么<code>Pending</code>的原因.继续下一步,处理这些依赖的错误.</p>
</li>
</ul>
<h3 id="安装Minio-Deployment"><a href="#安装Minio-Deployment" class="headerlink" title="安装Minio Deployment"></a>安装<code>Minio Deployment</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-deployment.yaml?raw=<span class="literal">true</span></span><br><span class="line">deployment.extensions/minio created</span><br><span class="line"></span><br><span class="line">~$ cat minio-standalone-deployment.yaml</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  <span class="comment"># This name uniquely identifies the Deployment</span></span><br><span class="line">  name: minio</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="comment"># Specifies the strategy used to replace old Pods by new ones</span></span><br><span class="line">    <span class="comment"># Refer: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy</span></span><br><span class="line">    <span class="built_in">type</span>: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        <span class="comment"># This label is used as a selector in Service definition</span></span><br><span class="line">        app: minio</span><br><span class="line">    spec:</span><br><span class="line">      <span class="comment"># Volumes used by this deployment</span></span><br><span class="line">      volumes:</span><br><span class="line">      - name: data</span><br><span class="line">        <span class="comment"># This volume is based on PVC</span></span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          <span class="comment"># Name of the PVC created earlier</span></span><br><span class="line">          claimName: minio-pv-claim</span><br><span class="line">      containers:</span><br><span class="line">      - name: minio</span><br><span class="line">        <span class="comment"># Volume mounts for this container</span></span><br><span class="line">        volumeMounts:</span><br><span class="line">        <span class="comment"># Volume 'data' is mounted to path '/data'</span></span><br><span class="line">        - name: data</span><br><span class="line">          mountPath: <span class="string">"/data"</span></span><br><span class="line">        <span class="comment"># Pulls the lastest Minio image from Docker Hub</span></span><br><span class="line">        image: minio/minio:RELEASE.2019-04-18T21-44-59Z</span><br><span class="line">        args:</span><br><span class="line">        - server</span><br><span class="line">        - /data</span><br><span class="line">        env:</span><br><span class="line">        <span class="comment"># MinIO access key and secret key</span></span><br><span class="line">        - name: MINIO_ACCESS_KEY</span><br><span class="line">          value: <span class="string">"minio"</span></span><br><span class="line">        - name: MINIO_SECRET_KEY</span><br><span class="line">          value: <span class="string">"minio123"</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">        <span class="comment"># Readiness probe detects situations when MinIO server instance</span></span><br><span class="line">        <span class="comment"># is not ready to accept traffic. Kubernetes doesn't forward</span></span><br><span class="line">        <span class="comment"># traffic to the pod while readiness checks fail.</span></span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /minio/health/ready</span><br><span class="line">            port: 9000</span><br><span class="line">          initialDelaySeconds: 120</span><br><span class="line">          periodSeconds: 20</span><br><span class="line">        <span class="comment"># Liveness probe detects situations where MinIO server instance</span></span><br><span class="line">        <span class="comment"># is not working properly and needs restart. Kubernetes automatically</span></span><br><span class="line">        <span class="comment"># restarts the pods if liveness checks fail.</span></span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /minio/health/live</span><br><span class="line">            port: 9000</span><br><span class="line">          initialDelaySeconds: 120</span><br><span class="line">          periodSeconds: 20</span><br><span class="line">~$ kubectl get deployment  --namespace default</span><br><span class="line">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">minio   0/1     1            0           82s</span><br></pre></td></tr></table></figure>
<h3 id="安装Minio-Service"><a href="#安装Minio-Service" class="headerlink" title="安装Minio Service"></a>安装<code>Minio Service</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl create -f https://github.com/minio/minio/blob/master/docs/orchestration/kubernetes/minio-standalone-service.yaml?raw=<span class="literal">true</span></span><br><span class="line">service/minio-service created</span><br><span class="line"></span><br><span class="line">~$ cat minio-standalone-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  <span class="comment"># This name uniquely identifies the service</span></span><br><span class="line">  name: minio-service</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: LoadBalancer</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9000</span><br><span class="line">      targetPort: 9000</span><br><span class="line">      protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    <span class="comment"># Looks for labels `app:minio` in the namespace and applies the spec</span></span><br><span class="line">    app: minio</span><br><span class="line"></span><br><span class="line">~$ kubectl get svc minio-service</span><br><span class="line">NAME            TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">minio-service   LoadBalancer   10.100.57.156   &lt;pending&gt;     9000:32552/TCP   10m</span><br><span class="line"><span class="comment"># 查看为什么会Pending</span></span><br><span class="line">~$ kubectl describe pod --namespace default -l app=minio</span><br><span class="line">Name:               minio-756cb7dff7-mcm6m</span><br><span class="line">Namespace:          default</span><br><span class="line">Priority:           0</span><br><span class="line">PriorityClassName:  &lt;none&gt;</span><br><span class="line">Node:               fe001/172.18.253.222</span><br><span class="line">Start Time:         Fri, 19 Apr 2019 15:20:30 +0800</span><br><span class="line">Labels:             app=minio</span><br><span class="line">                    pod-template-hash=756cb7dff7</span><br><span class="line">Annotations:        &lt;none&gt;</span><br><span class="line">Status:             Running</span><br><span class="line">IP:                 10.244.1.4</span><br><span class="line">Controlled By:      ReplicaSet/minio-756cb7dff7</span><br><span class="line">Containers:</span><br><span class="line">  minio:</span><br><span class="line">    Container ID:  docker://119535fa5ab172b5b2155c650dc51c2d12b3c02b1e28ab9e8301eb318ab969a7</span><br><span class="line">    Image:         minio/minio:RELEASE.2019-04-18T21-44-59Z</span><br><span class="line">    Image ID:      docker-pullable://minio/minio@sha256:a26e089732b85f8c312ff6346498acec763033b1ac85e74fc897f667939ea2aa</span><br><span class="line">    Port:          9000/TCP</span><br><span class="line">    Host Port:     0/TCP</span><br><span class="line">    Args:</span><br><span class="line">      server</span><br><span class="line">      /data</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Fri, 19 Apr 2019 15:20:51 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Liveness:       http-get http://:9000/minio/health/live delay=120s timeout=1s period=20s <span class="comment">#success=1 #failure=3</span></span><br><span class="line">    Readiness:      http-get http://:9000/minio/health/ready delay=120s timeout=1s period=20s <span class="comment">#success=1 #failure=3</span></span><br><span class="line">    Environment:</span><br><span class="line">      MINIO_ACCESS_KEY:  minio</span><br><span class="line">      MINIO_SECRET_KEY:  minio123</span><br><span class="line">    Mounts:</span><br><span class="line">      /data from data (rw)</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2vsh9 (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type              Status</span><br><span class="line">  Initialized       True</span><br><span class="line">  Ready             True</span><br><span class="line">  ContainersReady   True</span><br><span class="line">  PodScheduled      True</span><br><span class="line">Volumes:</span><br><span class="line">  data:</span><br><span class="line">    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim <span class="keyword">in</span> the same namespace)</span><br><span class="line">    ClaimName:  minio-pv-claim</span><br><span class="line">    ReadOnly:   <span class="literal">false</span></span><br><span class="line">  default-token-2vsh9:</span><br><span class="line">    Type:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default-token-2vsh9</span><br><span class="line">    Optional:    <span class="literal">false</span></span><br><span class="line">QoS Class:       BestEffort</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute <span class="keyword">for</span> 300s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute <span class="keyword">for</span> 300s</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason            Age                  From               Message</span><br><span class="line">  ----     ------            ----                 ----               -------</span><br><span class="line">  Warning  FailedScheduling  5m10s (x7 over 12m)  default-scheduler  0/3 nodes are available: 3 node(s) had taints that the pod didn\<span class="string">'t tolerate.</span></span><br><span class="line"><span class="string">  Normal   Scheduled         5m8s                 default-scheduler  Successfully assigned default/minio-756cb7dff7-mcm6m to fe001</span></span><br><span class="line"><span class="string">  Normal   Pulling           5m7s                 kubelet, fe001     Pulling image "minio/minio:RELEASE.2019-04-18T21-44-59Z"</span></span><br><span class="line"><span class="string">  Normal   Pulled            4m47s                kubelet, fe001     Successfully pulled image "minio/minio:RELEASE.2019-04-18T21-44-59Z"</span></span><br><span class="line"><span class="string">  Normal   Created           4m47s                kubelet, fe001     Created container minio</span></span><br><span class="line"><span class="string">  Normal   Started           4m47s                kubelet, fe001     Started container minio</span></span><br></pre></td></tr></table></figure>
<ul>
<li>如上所示,<code>Pending</code>原因是因为<code>Warning  FailedScheduling  5m10s (x7 over 12m)  default-scheduler  0/3 nodes are available: 3 node(s) had taints that the pod didn\&#39;t tolerate.</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get pod --namespace default -l app=minio</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">minio-756cb7dff7-k2sdk   1/1     Running   0          15m</span><br><span class="line"><span class="comment"># 在运行的容器中远程执行命令.下面的双横杠代表着kubectl命令项的结束.</span></span><br><span class="line">~$ kubectl <span class="built_in">exec</span> minio-756cb7dff7-k2sdk -- ping 8.8.8.8</span><br><span class="line">PING 8.8.8.8 (8.8.8.8): 56 data bytes</span><br><span class="line">64 bytes from 8.8.8.8: seq=1 ttl=41 time=25.684 ms</span><br><span class="line"><span class="comment"># 在容器中运行shell</span></span><br><span class="line">~$ kubectl <span class="built_in">exec</span> -it minio-756cb7dff7-k2sdk sh</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure>
<h2 id="通过Ingress暴露服务"><a href="#通过Ingress暴露服务" class="headerlink" title="通过Ingress暴露服务"></a>通过<code>Ingress</code>暴露服务</h2><ul>
<li>向集群外部的客户端公开服务的有使用<code>LoadBalancer</code>和<code>Ingress</code>两种方法.每个<code>LoadBalancer</code>服务都需要自己的负载均衡器,以及独有的公有IP的地址,而<code>Ingress</code>只需要一个公网IP就能为许多服务提供访问.当客户端向<code>Ingress</code>发送<code>Http</code>请求时,<code>Ingress</code>会根据请求的主机名和路径决定请求转发到的服务.<code>Ingress在</code>网络栈的(HTTP)的应用层操作,并且可以提供一些服务不能实现的功能.如基于<code>cookie</code>的<code>session affinity</code>等功能.</li>
</ul>
<h1 id="Traefik反向代理"><a href="#Traefik反向代理" class="headerlink" title="Traefik反向代理"></a><code>Traefik</code>反向代理</h1><ul>
<li>参考链接:<ul>
<li><a href="https://github.com/traefik/traefik" target="_blank" rel="noopener">traefik</a></li>
<li><a href="https://dev.to/maymeow/static-sites-with-minio-and-s3www-3feh" target="_blank" rel="noopener">Static Sites With Minio and S3www</a></li>
<li><a href="https://blog.sethcorker.com/traefik-routing-for-web-apps/" target="_blank" rel="noopener">Using Traefik for routing paths to web apps</a></li>
</ul>
</li>
<li><code>Traefik</code>是一款云原生反向代理、负载均衡服务,使用<code>golang</code>实现的.和<code>nginx</code>最大的不同是,它支持自动化更新反向代理和负载均衡配置.并且支持多种后端:<ul>
<li>Docker / Swarm mode</li>
<li>Kubernetes</li>
<li>Marathon</li>
<li>Rancher (Metadata)</li>
<li>File</li>
</ul>
</li>
</ul>
<h2 id="快速安装测试"><a href="#快速安装测试" class="headerlink" title="快速安装测试"></a>快速安装测试</h2><ul>
<li><p>下载一份<code>Traefik</code>的配置,可以从这里复制一份<a href="https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml" target="_blank" rel="noopener">简单配置</a>,或者去到<a href="https://github.com/traefik/traefik/releases" target="_blank" rel="noopener">https://github.com/traefik/traefik/releases</a>下载一个<code>Traefik</code>的二进制的程序,运行如下命令生成它:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ ./traefik -c traefik.toml</span><br></pre></td></tr></table></figure>
</li>
<li><p>直接<code>Docker</code>运行测试,浏览器打开<code>http://127.0.0.1:8080/dashboard/#/</code>进入控制台查看.它有几个重要的核心组件:</p>
<ul>
<li>Providers</li>
<li>Entrypoints</li>
<li>Routers</li>
<li>Services</li>
<li>Middlewares<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ docker run -d -p 8080:8080 -p 80:80 -v <span class="variable">$PWD</span>/traefik.toml:/etc/traefik/traefik.toml traefik</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h2 id="docker-compose测试说明"><a href="#docker-compose测试说明" class="headerlink" title="docker-compose测试说明"></a><code>docker-compose</code>测试说明</h2><ul>
<li>下面是用一个简单的组合配置测试,来直观理解说明<code>Traefik</code>的用途与使用场景,这里使用<code>v2.5</code>的版本,与旧的<code>v1.2</code>是有差别的.测试的目录结构如下:</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">~$ tree</span><br><span class="line">.</span><br><span class="line">├── minio</span><br><span class="line">│   └── docker-compose.yml</span><br><span class="line">├── traefik</span><br><span class="line">│   ├── docker-compose-v2.yml</span><br><span class="line">│   ├── docker-compose.yml</span><br><span class="line">│   └── traefik.toml</span><br><span class="line">└── whoami-app</span><br><span class="line">    ├── docker-compose-v2.yml</span><br><span class="line">    └── docker-compose.yml</span><br></pre></td></tr></table></figure>
<ul>
<li><p>运行<code>Traefik</code>实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">traefik$ cat docker-compose-v2.yml</span><br><span class="line">version: <span class="string">'3'</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  reverse-proxy:</span><br><span class="line">    <span class="comment"># The official v2 Traefik docker image</span></span><br><span class="line">    image: traefik:v2.5</span><br><span class="line">    <span class="comment"># Enables the web UI and tells Traefik to listen to docker</span></span><br><span class="line">    <span class="built_in">command</span>: --api.insecure=<span class="literal">true</span> --providers.docker</span><br><span class="line">    ports:</span><br><span class="line">      <span class="comment"># The HTTP port</span></span><br><span class="line">      - <span class="string">"80:80"</span></span><br><span class="line">      <span class="comment"># The Web UI (enabled by --api.insecure=true)</span></span><br><span class="line">      - <span class="string">"8080:8080"</span></span><br><span class="line">    volumes:</span><br><span class="line">      <span class="comment"># So that Traefik can listen to the Docker events</span></span><br><span class="line">      - /var/run/docker.sock:/var/run/docker.sock</span><br><span class="line">traefik$ docker-compose -f docker-compose-v2.yml up -d</span><br><span class="line">Creating network <span class="string">"traefik_default"</span> with the default driver</span><br><span class="line">Creating traefik_reverse-proxy_1 ... <span class="keyword">done</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>运行3个测试实例(traefik/whoami)</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">whoami-app$ cat docker-compose-v2.yml</span><br><span class="line">version: <span class="string">'3'</span></span><br><span class="line">services:</span><br><span class="line">  whoami:</span><br><span class="line">    <span class="comment"># A container that exposes an API to show its IP address</span></span><br><span class="line">    image: traefik/whoami</span><br><span class="line">    networks:</span><br><span class="line">      - traefik_default</span><br><span class="line">    labels:</span><br><span class="line">      - traefik.docker.network=traefik_default</span><br><span class="line">      - traefik.http.routers.whoami.rule=Host(`whoami.docker.localhost`)</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  traefik_default:</span><br><span class="line">    external: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">whoami-app$ docker-compose -f docker-compose-v2.yml up -d --scale whoami=3</span><br><span class="line">Starting whoami-app_whoami_1 ... <span class="keyword">done</span></span><br><span class="line">Creating whoami-app_whoami_2 ... <span class="keyword">done</span></span><br><span class="line">Creating whoami-app_whoami_3 ... <span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>可以通过浏览器的页面<code>http://127.0.0.1:8080/dashboard/#/http/services</code>查看服务的状态,也可以通过如下命令查看.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~$ curl  http://localhost:8080/api/rawdata | jq -c <span class="string">'.services'</span></span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  1829  100  1829    0     0  1786k      0 --:--:-- --:--:-- --:--:-- 1786k</span><br><span class="line">&#123;<span class="string">"api@internal"</span>:&#123;<span class="string">"status"</span>:<span class="string">"enabled"</span>,<span class="string">"usedBy"</span>:[<span class="string">"api@internal"</span>]&#125;,<span class="string">"dashboard@internal"</span>:&#123;<span class="string">"status"</span>:<span class="string">"enabled"</span>,<span class="string">"usedBy"</span>:[<span class="string">"dashboard@internal"</span>]&#125;,<span class="string">"noop@internal"</span>:&#123;<span class="string">"status"</span>:<span class="string">"enabled"</span>&#125;,<span class="string">"reverse-proxy-traefik@docker"</span>:&#123;<span class="string">"loadBalancer"</span>:&#123;<span class="string">"servers"</span>:[&#123;<span class="string">"url"</span>:<span class="string">"http://172.30.0.2:80"</span>&#125;],<span class="string">"passHostHeader"</span>:<span class="literal">true</span>&#125;,<span class="string">"status"</span>:<span class="string">"enabled"</span>,<span class="string">"usedBy"</span>:[<span class="string">"reverse-proxy-traefik@docker"</span>],<span class="string">"serverStatus"</span>:&#123;<span class="string">"http://172.30.0.2:80"</span>:<span class="string">"UP"</span>&#125;&#125;,<span class="string">"whoami-whoami-app@docker"</span>:&#123;<span class="string">"loadBalancer"</span>:&#123;<span class="string">"servers"</span>:[&#123;<span class="string">"url"</span>:<span class="string">"http://172.31.0.4:80"</span>&#125;,&#123;<span class="string">"url"</span>:<span class="string">"http://172.31.0.2:80"</span>&#125;,&#123;<span class="string">"url"</span>:<span class="string">"http://172.31.0.3:80"</span>&#125;],<span class="string">"passHostHeader"</span>:<span class="literal">true</span>&#125;,<span class="string">"status"</span>:<span class="string">"enabled"</span>,<span class="string">"usedBy"</span>:[<span class="string">"whoami@docker"</span>],<span class="string">"serverStatus"</span>:&#123;<span class="string">"http://172.31.0.2:80"</span>:<span class="string">"UP"</span>,<span class="string">"http://172.31.0.3:80"</span>:<span class="string">"UP"</span>,<span class="string">"http://172.31.0.4:80"</span>:<span class="string">"UP"</span>&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>或者是这样</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">~$ curl -H Host:whoami.docker.localhost http://127.0.0.1</span><br><span class="line">Hostname: 4c9f9a107136</span><br><span class="line">IP: 127.0.0.1</span><br><span class="line">IP: 172.19.0.6</span><br><span class="line">RemoteAddr: 172.19.0.1:46902</span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: whoami.docker.localhost</span><br><span class="line">User-Agent: curl/7.74.0</span><br><span class="line">Accept: */*</span><br><span class="line">Accept-Encoding: gzip</span><br><span class="line">X-Forwarded-For: 172.19.0.1</span><br><span class="line">X-Forwarded-Host: whoami.docker.localhost</span><br><span class="line">X-Forwarded-Port: 80</span><br><span class="line">X-Forwarded-Proto: http</span><br><span class="line">X-Forwarded-Server: 8a986b075043</span><br><span class="line">X-Real-Ip: 172.19.0.1</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="docker-compose安装MinIO"><a href="#docker-compose安装MinIO" class="headerlink" title="docker-compose安装MinIO"></a><code>docker-compose</code>安装<code>MinIO</code></h3><ul>
<li><p>运行一个稍微复杂的<code>MinIO</code>的服务实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">"3"</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  minio:</span><br><span class="line">    <span class="comment"># Please use fixed versions :D</span></span><br><span class="line">    image: minio/minio</span><br><span class="line">    hostname: minio</span><br><span class="line">    networks:</span><br><span class="line">      - traefik_default</span><br><span class="line">    volumes:</span><br><span class="line">      - <span class="variable">$PWD</span>/minio-data:/data</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">      - server</span><br><span class="line">      - /data</span><br><span class="line">      - --console-address</span><br><span class="line">      - <span class="string">":9001"</span></span><br><span class="line">    expose:</span><br><span class="line">      - 9000</span><br><span class="line">      - 9001</span><br><span class="line">    environment:</span><br><span class="line">      - MINIO_ROOT_USER=minio</span><br><span class="line">      - MINIO_ROOT_PASSWORD=minio123</span><br><span class="line">      - APP_NAME=minio</span><br><span class="line">      <span class="comment"># Do NOT use MINIO_DOMAIN or MINIO_SERVER_URL with Traefik.</span></span><br><span class="line">      <span class="comment"># All Routing is done by Traefik, just tell minio where to redirect to.</span></span><br><span class="line">      - MINIO_BROWSER_REDIRECT_URL=http://minio-console.localhost</span><br><span class="line">    labels:</span><br><span class="line">      - traefik.enable=<span class="literal">true</span></span><br><span class="line">      - traefik.docker.network=traefik_default</span><br><span class="line">      - traefik.http.routers.minio.rule=Host(`minio.localhost`)</span><br><span class="line">      - traefik.http.routers.minio-console.rule=Host(`minio-console.localhost`)</span><br><span class="line">      - traefik.http.routers.minio.service=minio</span><br><span class="line">      - traefik.http.services.minio.loadbalancer.server.port=9000</span><br><span class="line">      - traefik.http.services.minio-console.loadbalancer.server.port=9001</span><br><span class="line">      - traefik.http.routers.minio-console.service=minio-console</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  traefik_default:</span><br><span class="line">    external: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">minio$ docker-compose up -d</span><br><span class="line">Creating minio_minio_1 ... <span class="keyword">done</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>运行上面实例后,可以通浏览器打开<code>http://minio-console.localhost</code>,输入<code>minio:minio123</code>登录到<code>minIO</code>的控制台页面.为什么会通过<code>minio-console.localhost</code>这样一个域名,就可以反向代理内部的服务了.这里可以打开<code>http://localhost:8080/dashboard/#/http/routers</code>看到相应的路由,也可以用下面命令查看有那些路由:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">~$ curl http://localhost:8080/api/rawdata | jq   <span class="string">'.routers[] | .service'</span></span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  2509    0  2509    0     0  2450k      0 --:--:-- --:--:-- --:--:-- 2450k</span><br><span class="line"><span class="string">"api@internal"</span></span><br><span class="line"><span class="string">"dashboard@internal"</span></span><br><span class="line"><span class="string">"minio-console"</span></span><br><span class="line"><span class="string">"minio"</span></span><br><span class="line"><span class="string">"reverse-proxy-traefik"</span></span><br><span class="line"><span class="string">"whoami-whoami-app"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>这里测试时需要注意一个点,如果把<code>minio</code>与<code>traefik</code>等服务描述,写在同一个<code>docker-compose.yml</code>文件里,是不需要<br>指定<code>networks</code>段的,如果分开写的,是需要声明与<code>traefik</code>的服务在同一个网络域内,上面的测试实例中,<br><code>docker-compose</code>启动<code>traefik</code>服务时,会默认创建一个名为<code>traefik_default</code>网络域.所以这里在上述<br>实例中:<code>whoami,minio</code>中,都声明定义了<code>networks</code>的字段,本机<code>Docker</code>网络列表如下:</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">~$ docker network ls</span><br><span class="line">NETWORK ID     NAME                 DRIVER    SCOPE</span><br><span class="line">f8c2befaa42f   bridge               bridge    <span class="built_in">local</span></span><br><span class="line">f27beded9896   host                 host      <span class="built_in">local</span></span><br><span class="line">244ab53cbc48   none                 null      <span class="built_in">local</span></span><br><span class="line">18ddc4985478   traefik_default      bridge    <span class="built_in">local</span></span><br><span class="line">1c5f5a863ef9   whoami-app_default   bridge    <span class="built_in">local</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p><code>Traefik</code>创建路由规则有多种方式,比如:</p>
<ul>
<li>原生<code>Ingress</code>写法</li>
<li>使用<code>CRD IngressRoute</code>方式</li>
<li>使用<code>GatewayAPI</code>的方式</li>
</ul>
</li>
<li><p>停掉测试实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">whoami-app$ docker-compose -f docker-compose-v2.yml down</span><br><span class="line">Stopping whoami-app_whoami_1 ... <span class="keyword">done</span></span><br><span class="line">Stopping whoami-app_whoami_3 ... <span class="keyword">done</span></span><br><span class="line">Stopping whoami-app_whoami_2 ... <span class="keyword">done</span></span><br><span class="line">Removing whoami-app_whoami_1 ... <span class="keyword">done</span></span><br><span class="line">Removing whoami-app_whoami_3 ... <span class="keyword">done</span></span><br><span class="line">Removing whoami-app_whoami_2 ... <span class="keyword">done</span></span><br><span class="line">Removing network whoami-app_default</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="MC客户端"><a href="#MC客户端" class="headerlink" title="MC客户端"></a><code>MC</code>客户端</h3><ul>
<li><a href="https://docs.min.io/docs/minio-client-complete-guide.html" target="_blank" rel="noopener">MinIO Client Complete Guide Slack</a><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.min.io/client/mc/release/linux-amd64/mc</span><br><span class="line">chmod +x mc</span><br><span class="line">./mc --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./mc config host add mystorage http://minio.localhost test1234access test1234secret --api s3v4</span><br><span class="line">mc: Configuration written to `/home/michael/.mc/config.json`. Please update your access credentials.</span><br><span class="line">mc: Successfully created `/home/michael/.mc/share`.</span><br><span class="line">mc: Initialized share uploads `/home/michael/.mc/share/uploads.json` file.</span><br><span class="line">mc: Initialized share downloads `/home/michael/.mc/share/downloads.json` file.</span><br><span class="line">Added `mystorage` successfully.</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~$ ./mc admin info play/</span><br><span class="line">●  play.min.io</span><br><span class="line">   Uptime: 2 days</span><br><span class="line">   Version: 2021-12-10T23:03:39Z</span><br><span class="line">   Network: 1/1 OK</span><br><span class="line">   Drives: 4/4 OK</span><br><span class="line"></span><br><span class="line">11 GiB Used, 392 Buckets, 8,989 Objects</span><br><span class="line">4 drives online, 0 drives offline</span><br></pre></td></tr></table></figure>
<h3 id="S3客户端连接测试MinIO"><a href="#S3客户端连接测试MinIO" class="headerlink" title="S3客户端连接测试MinIO"></a><code>S3</code>客户端连接测试<code>MinIO</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ pip3 install awscli</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">minio$ aws configure --profile minio</span><br><span class="line">AWS Access Key ID [None]: test1234minio</span><br><span class="line">AWS Secret Access Key [None]: test1234minio</span><br><span class="line">Default region name [None]: minio-lan</span><br><span class="line">Default output format [None]: json</span><br></pre></td></tr></table></figure>
<h1 id="Helm包管理器"><a href="#Helm包管理器" class="headerlink" title="Helm包管理器"></a><code>Helm</code>包管理器</h1><ul>
<li><a href="https://github.com/helm/helm" target="_blank" rel="noopener">Helm</a>是<code>k8s</code>的包管理器,它可以类比为<code>Debian,Ubuntu</code>的<code>apt</code>.<code>Red Hat</code>的<code>yum</code>,<code>Python</code>中的<code>pip</code>.<code>Nodejs</code>的<code>npm</code>包管理器.<code>Helm</code>可以理解为<code>Kubernetes</code>的包管理工具,可以方便地发现、共享和使用为<code>Kubernetes</code>构建的应用,它包含几个基本概念:<ul>
<li><code>.Chart</code>:一个<code>Helm</code>包,其中包含了运行一个应用所需要的镜像、依赖和资源定义等,还可能包含<code>Kubernetes</code>集群中的服务定义,类似<code>Homebrew</code>中的<code>formula</code>,<code>APT</code>的<code>dpkg</code>或者<code>Yum</code>的<code>rpm</code>文件.</li>
<li><code>.Release</code>:在<code>Kubernetes</code>集群上运行的<code>Chart</code>的一个实例.在同一个集群上,一个<code>Chart</code>可以安装很多次.每次安装都会创建一个新的<code>Release</code>. <code>MySQL Chart</code>,如果想在服务器上运行两个数据库,就可以把这个<code>Chart</code>安装两次.每次安装都会生成自己的<code>Release</code>,会有自己的<code>Release</code>名称.</li>
<li><code>.Repository</code>:用于发布和存储<code>Chart</code>的仓库.</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载一个最版本,把它解压到/usr/local/bin</span></span><br><span class="line">~$ wget -c https://storage.googleapis.com/kubernetes-helm/helm-v2.13.1-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">~$ helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:<span class="string">"v2.13.1"</span>, GitCommit:<span class="string">"618447cbf203d147601b4b9bd7f8c37a5d39fbb4"</span>, GitTreeState:<span class="string">"clean"</span>&#125;</span><br><span class="line">Error: could not find tiller</span><br><span class="line"></span><br><span class="line">~$ helm completion bash &gt; ~/.helmrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"source ~/.helmrc"</span> &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>
<h2 id="安装Tiller服务器"><a href="#安装Tiller服务器" class="headerlink" title="安装Tiller服务器"></a>安装<code>Tiller</code>服务器</h2><ul>
<li><p><a href="https://yq.aliyun.com/articles/159601" target="_blank" rel="noopener">利用Helm简化Kubernetes应用部署</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">~$ helm init</span><br><span class="line">Creating /home/lcy/.helm</span><br><span class="line">Creating /home/lcy/.helm/repository</span><br><span class="line">Creating /home/lcy/.helm/repository/cache</span><br><span class="line">Creating /home/lcy/.helm/repository/<span class="built_in">local</span></span><br><span class="line">Creating /home/lcy/.helm/plugins</span><br><span class="line">Creating /home/lcy/.helm/starters</span><br><span class="line">Creating /home/lcy/.helm/cache/archive</span><br><span class="line">Creating /home/lcy/.helm/repository/repositories.yaml</span><br><span class="line">Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com</span><br><span class="line">Error: Looks like <span class="string">"https://kubernetes-charts.storage.googleapis.com"</span> is not a valid chart repository or cannot be reached: <span class="built_in">read</span> tcp 172.18.127.186:54980-&gt;216.58.199.16:443: <span class="built_in">read</span>: connection reset by peer</span><br></pre></td></tr></table></figure>
</li>
<li><p>如上所示,无法连接到官方的服务器,国内利用阿里云源来安装</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">~$ helm init --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.13.1 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><span class="line">Creating /home/lcy/.helm/repository/repositories.yaml</span><br><span class="line">Adding stable repo with URL: https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><span class="line">Adding <span class="built_in">local</span> repo with URL: http://127.0.0.1:8879/charts</span><br><span class="line"><span class="variable">$HELM_HOME</span> has been configured at /home/lcy/.helm.</span><br><span class="line"></span><br><span class="line">Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.</span><br><span class="line"></span><br><span class="line">Please note: by default, Tiller is deployed with an insecure <span class="string">'allow unauthenticated users'</span> policy.</span><br><span class="line">To prevent this, run `helm init` with the --tiller-tls-verify flag.</span><br><span class="line">For more information on securing your installation see: https://docs.helm.sh/using_helm/<span class="comment">#securing-your-helm-installation</span></span><br><span class="line">Happy Helming!</span><br><span class="line"></span><br><span class="line">~$ helm init --upgrade</span><br><span class="line"><span class="variable">$HELM_HOME</span> has been configured at /home/lcy/.helm.</span><br><span class="line"></span><br><span class="line">Tiller (the Helm server-side component) has been upgraded to the current version.</span><br><span class="line">Happy Helming!</span><br><span class="line"><span class="comment"># 查找charts</span></span><br><span class="line">~$ helm search</span><br><span class="line">NAME                            CHART VERSION   APP VERSION     DESCRIPTION</span><br><span class="line">stable/acs-engine-autoscaler    2.1.3           2.1.1           Scales worker nodes within agent pools</span><br><span class="line">stable/aerospike                0.1.7           v3.14.1.2       A Helm chart <span class="keyword">for</span> Aerospike <span class="keyword">in</span> Kubernetes</span><br><span class="line">stable/anchore-engine           0.1.3           0.1.6           Anchore container analysis and policy evaluation engine s...</span><br><span class="line">stable/artifactory              7.0.3           5.8.4           Universal Repository Manager supporting all major packagi...</span><br><span class="line">stable/artifactory-ha           0.1.0           5.8.4           Universal Repository Manager supporting all major packagi...</span><br><span class="line">[...]</span><br><span class="line"><span class="comment"># 更新仓库</span></span><br><span class="line">~$ helm repo update</span><br><span class="line">Hang tight <span class="keyword">while</span> we grab the latest from your chart repositories...</span><br><span class="line">...Skip <span class="built_in">local</span> chart repository</span><br><span class="line">...Successfully got an update from the <span class="string">"stable"</span> chart repository</span><br><span class="line">Update Complete. ⎈ Happy Helming!⎈</span><br><span class="line"></span><br><span class="line"><span class="comment"># 仓库地址</span></span><br><span class="line">~$ helm repo list</span><br><span class="line">NAME  	URL</span><br><span class="line">stable	https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><span class="line"><span class="built_in">local</span> 	http://127.0.0.1:8879/charts</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="使用Helm-Chart部署MinIO"><a href="#使用Helm-Chart部署MinIO" class="headerlink" title="使用Helm Chart部署MinIO"></a>使用<code>Helm Chart</code>部署<code>MinIO</code></h2><ul>
<li><a href="https://docs.min.io/cn/deploy-minio-on-kubernetes.html" target="_blank" rel="noopener">MinIO中文手册</a></li>
<li>默认<code>standaline</code>模式下,需要开启<code>Beta API</code>的<code>Kubernetes 1.4+</code>.如果没有出错就会运行成功,如下所示.<br>如果出错,按照后面的错误处理.<br><code>accessKey</code>默认<code>access key    AKIAIOSFODNN7EXAMPLE</code><br><code>secretKey</code>默认<code>secret key    wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">~$ helm install stable/minio</span><br><span class="line">NAME:   snug-elk</span><br><span class="line">LAST DEPLOYED: Mon Apr 15 14:07:10 2019</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME                      DATA  AGE</span><br><span class="line">snug-elk-minio-config-cm  2     0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/PersistentVolumeClaim</span><br><span class="line">NAME            STATUS   VOLUME  CAPACITY  ACCESS MODES  STORAGECLASS  AGE</span><br><span class="line">snug-elk-minio  Pending  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                             READY  STATUS   RESTARTS  AGE</span><br><span class="line">snug-elk-minio-7b9878bb66-mmx9n  0/1    Pending  0         0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Secret</span><br><span class="line">NAME                 TYPE    DATA  AGE</span><br><span class="line">snug-elk-minio-user  Opaque  2     0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME                TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)         AGE</span><br><span class="line">snug-elk-minio-svc  LoadBalancer  10.103.48.186  &lt;pending&gt;    9000:32076/TCP  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Deployment</span><br><span class="line">NAME            READY  UP-TO-DATE  AVAILABLE  AGE</span><br><span class="line">snug-elk-minio  0/1    1           0          0s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line"></span><br><span class="line">Minio can be accessed via port 9000 on an external IP address. Get the service external IP address by:</span><br><span class="line">kubectl get svc --namespace default -l app=snug-elk-minio</span><br><span class="line"></span><br><span class="line">Note that the public IP may take a couple of minutes to be available.</span><br><span class="line"></span><br><span class="line">You can now access Minio server on http://&lt;External-IP&gt;:9000. Follow the below steps to connect to Minio server with mc client:</span><br><span class="line"></span><br><span class="line">  1. Download the Minio mc client - https://docs.minio.io/docs/minio-client-quickstart-guide</span><br><span class="line"></span><br><span class="line">  2. mc config host add snug-elk-minio-local http://&lt;External-IP&gt;:9000 AKIAIOSFODNN7EXAMPLE wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY S3v4</span><br><span class="line"></span><br><span class="line">  3. mc ls snug-elk-minio-local</span><br><span class="line"></span><br><span class="line">Alternately, you can use your browser or the Minio SDK to access the server - https://docs.minio.io/categories/17</span><br></pre></td></tr></table></figure>
<ul>
<li>查看Release对象</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get service snug-elk-minio-svc</span><br><span class="line">NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">snug-elk-minio-svc   LoadBalancer   10.103.48.186   &lt;pending&gt;     9000:32076/TCP   3m7s</span><br><span class="line"></span><br><span class="line">~$ kubectl  get pods</span><br><span class="line">NAME                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">store-minio-75bb89c596-74nz9   0/1     Pending   0          17m</span><br><span class="line"></span><br><span class="line">~$ kubectl   describe pod  store-minio-75bb89c596-74nz9</span><br><span class="line">Name:               store-minio-75bb89c596-74nz9</span><br><span class="line">[...]</span><br><span class="line"></span><br><span class="line">~$ helm list</span><br><span class="line">NAME            REVISION        UPDATED                         STATUS          CHART           APP VERSION     NAMESPACE</span><br><span class="line">snug-elk        1               Mon Apr 15 14:07:10 2019        DEPLOYED        minio-0.5.5                     default</span><br></pre></td></tr></table></figure>
<h3 id="安装MinIO客户端"><a href="#安装MinIO客户端" class="headerlink" title="安装MinIO客户端"></a>安装<code>MinIO</code>客户端</h3><ul>
<li>按照上面安装服务器的<code>NOTES</code>,安装与配置它的命令行客户端.<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~$ wget https://dl.minio.io/client/mc/release/linux-amd64/mc</span><br><span class="line">~$ sudo mv mc /usr/<span class="built_in">local</span>/bin &amp;&amp; chmod +x /usr/<span class="built_in">local</span>/bin/mc</span><br><span class="line">~$ kubectl get svc --namespace default -l app=snug-elk-minio</span><br><span class="line">NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">snug-elk-minio-svc   LoadBalancer   10.103.48.186   &lt;pending&gt;     9000:32076/TCP   25h</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="安装集群监控DashBoard"><a href="#安装集群监控DashBoard" class="headerlink" title="安装集群监控DashBoard"></a>安装集群监控<code>DashBoard</code></h2><ul>
<li><a href="https://github.com/kubernetes/dashboard/wiki/Installation" target="_blank" rel="noopener">DashBoard Installation</a></li>
<li><a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/" target="_blank" rel="noopener">Web UI (Dashboard)</a></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>
<ul>
<li>查看安装是否成功.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl  --namespace=kube-system get pod -l k8s-app=kubernetes-dashboard</span><br><span class="line">NAME                                    READY   STATUS             RESTARTS   AGE</span><br><span class="line">kubernetes-dashboard-5f7b999d65-m2zmt   0/1     ImagePullBackOff   0          10m</span><br><span class="line"></span><br><span class="line">~$ kubectl  --namespace=kube-system describe  pod -l k8s-app=kubernetes-dashboard | grep <span class="string">"Events"</span> -A +10</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age                  From               Message</span><br><span class="line">  ----     ------     ----                 ----               -------</span><br><span class="line">  Normal   Scheduled  14m                  default-scheduler  Successfully assigned kube-system/kubernetes-dashboard-5f7b999d65-m2zmt to dig001</span><br><span class="line">  Normal   Pulling    11m (x4 over 14m)    kubelet, dig001    Pulling image <span class="string">"k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1"</span></span><br><span class="line">  Warning  Failed     11m (x4 over 13m)    kubelet, dig001    Failed to pull image <span class="string">"k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1"</span>: rpc error: code = Unknown desc = Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">  Warning  Failed     11m (x4 over 13m)    kubelet, dig001    Error: ErrImagePull</span><br><span class="line">  Warning  Failed     11m (x6 over 13m)    kubelet, dig001    Error: ImagePullBackOff</span><br><span class="line">  Normal   BackOff    4m5s (x36 over 13m)  kubelet, dig001    Back-off pulling image <span class="string">"k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>根<code>kubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard)</code>下面修改它的镜像地址,替换成国内的阿里云的地址.</li>
<li>使用<code>kubectl  edit deployment/kubernetes-dashboard -n kube-system</code>打开编辑,把<code>k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1</code>替换成<code>registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1</code>,保存退出.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改后,安装成了.</span></span><br><span class="line">~$ kubectl  --namespace=kube-system get deployment -l k8s-app=kubernetes-dashboard</span><br><span class="line">NAME                   READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">kubernetes-dashboard   1/1     1            1           51m</span><br><span class="line">~$ kubectl  --namespace=kube-system get pod -l k8s-app=kubernetes-dashboard</span><br><span class="line">NAME                                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">kubernetes-dashboard-5d9599dc98-gj8w7   1/1     Running   0          99s</span><br><span class="line">~$ kubectl  --namespace=kube-system get svc -l k8s-app=kubernetes-dashboard</span><br><span class="line">NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes-dashboard   ClusterIP   10.107.85.75   &lt;none&gt;        443/TCP   49m</span><br></pre></td></tr></table></figure>
<h3 id="Proxy加SSH转发访问方式"><a href="#Proxy加SSH转发访问方式" class="headerlink" title="Proxy加SSH转发访问方式"></a><code>Proxy</code>加<code>SSH</code>转发访问方式</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k8s的服务器上</span></span><br><span class="line">~$ kubectl  proxy</span><br><span class="line">Starting to serve on 127.0.0.1:8001</span><br><span class="line"><span class="comment"># 控制主机上运行下面命令,再从浏览器里打开http://127.0.0.1:8001/就能访问到DashBoard</span></span><br><span class="line">~$ ssh 8001:localhost:8001 &lt;user@k8s-server&gt; -Nf</span><br></pre></td></tr></table></figure>
<h3 id="修改Service端口类型"><a href="#修改Service端口类型" class="headerlink" title="修改Service端口类型"></a>修改<code>Service</code>端口类型</h3><ul>
<li><p>通过<code>kubectl --namespace=kube-system edit svc kubernetes-dashboard</code>打开编辑,把<code>type: ClusterIP</code>替换成<code>type: NodePort</code>.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl --namespace=kube-system edit svc kubernetes-dashboard</span><br><span class="line">~$ kubectl --namespace=kube-system get  svc kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.107.85.75   &lt;none&gt;        443:31690/TCP   65m</span><br></pre></td></tr></table></figure>
</li>
<li><p>如上所示可以通<code>https://&lt;service-host&gt;:31690/</code>访问到DashBoard.</p>
</li>
</ul>
<h3 id="访问认证"><a href="#访问认证" class="headerlink" title="访问认证"></a>访问认证</h3><ul>
<li><a href="https://github.com/kubernetes/dashboard/wiki/Creating-sample-user" target="_blank" rel="noopener">Creating sample user</a></li>
<li><a href="https://github.com/kubernetes/dashboard/wiki/Access-control#authorization-header" target="_blank" rel="noopener">Access control</a></li>
<li>第一次打开<code>DashBoard</code>会提示两种登录方式,<code>Kubeconfig</code>与<code>Token</code>.下面参照<a href="https://github.com/kubernetes/dashboard/wiki/Creating-sample-user" target="_blank" rel="noopener">Creating sample user</a>安装一下.</li>
</ul>
<h4 id="创建服务帐号"><a href="#创建服务帐号" class="headerlink" title="创建服务帐号"></a>创建服务帐号</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">~$ cat admin-user.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">~$ kubectl create -f admin-user.yaml</span><br><span class="line"></span><br><span class="line">~$ kubectl -n kube-system describe secret $(kubectl -n kube-system  get secret | grep admin | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line">Name:         admin-user-token-7dj2c</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: a65538aa-673b-11e9-b8a2-00163e027e39</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTdkajJjIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJhNjU1MzhhYS02NzNiLTExZTktYjhhMi0wMDE2M2UwMjdlMzkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.eW_YSgn_kTIQDcbB51k8HaY9LABeFg5mFFPJykYgsoyxZH_b80WEcDZn4Z4Ix2BJvhK1sBESfSa_Qn1yN5pcIzUMROIYvBGZBSnMmw2VsSpQMUTJ1ha43ql-GKCz15ro1VrhyeWeCtiVTILA0Z0DwfgO2skjY2x1KO_76sDR7r66frZDjGmgYTm-b3E6RdcETB41Wjjuj-nt3b3ZblkBr3QDKP-tlvnW_nr7LcmgF7etjU8qK_W3fj-LB_BnWRpRiamQeXLNJuC-Dq42x00gAzQuVg17rDcEiKxJWmDYYsojvm7Xg0fSwXLCdBfgysYCz5PMR05dT0QU0iYO7z_Cow</span><br></pre></td></tr></table></figure>
<ul>
<li>打开DashBoard首页,填入上面的<code>token</code>值.</li>
</ul>
<h4 id="创建集群角色绑定"><a href="#创建集群角色绑定" class="headerlink" title="创建集群角色绑定"></a>创建集群角色绑定</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">~$ cat dashboard-admin.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">~$ kubectl create -f dashboard-admin.yaml</span><br><span class="line"></span><br><span class="line">~$ kubectl -n kube-system describe secret $(kubectl -n kube-system  get secret | grep <span class="string">"kubernetes-dashboard-token"</span> |awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line">Name:         kubernetes-dashboard-token-ftk96</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: kubernetes-dashboard</span><br><span class="line">              kubernetes.io/service-account.uid: ba35db4d-672d-11e9-b8a2-00163e027e39</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi1mdGs5NiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImJhMzVkYjRkLTY3MmQtMTFlOS1iOGEyLTAwMTYzZTAyN2UzOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.gnspFBWcou3-EgMsSPPQqSt1fwWne6tLCNgHa0yrQLEH9DDRgDQh1mBDne4Z2M-s3FPlTV9DI77QneanA12jHrpLHRohQSlyiz8Pv3xa7JRb7Hfyj5PhbSlX2KtTbOlVvAdlFttFi3vw-fbUJWcALEmogwa7jnlR233slJLjZ8nAA9xsE-gr4_zYmZ2VhYGfH0dAs2H2aCklRl2Sy5VQpoDlGjKH82-FcCrLwGQyLpAA9tr0H7pivGIFqO46PWR0aBLiT1BBkmjoQJkDPy0qRxi90nG1WyFnDLHYK6BRDTZ4G-J3QhAiAK0su-7i6rJhMKm-FbnYXULIstW1LyO4tg</span><br></pre></td></tr></table></figure>
<h3 id="更新Dashboard"><a href="#更新Dashboard" class="headerlink" title="更新Dashboard"></a>更新<code>Dashboard</code></h3><ul>
<li>安装<code>Dashboard</code>它不会自动更新复盖本地旧的版本,必须要手动清除的旧的版本再安装新的版本.<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="官方快速入门实例教程"><a href="#官方快速入门实例教程" class="headerlink" title="官方快速入门实例教程"></a>官方快速入门实例教程</h1><ul>
<li><a href="https://github.com/kubernetes/examples" target="_blank" rel="noopener">https://github.com/kubernetes/examples</a></li>
</ul>
<h2 id="Guestbook实例"><a href="#Guestbook实例" class="headerlink" title="Guestbook实例"></a><code>Guestbook</code>实例</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">~$ git <span class="built_in">clone</span> https://github.com/kubernetes/examples</span><br><span class="line">~$ <span class="built_in">cd</span> exmaples</span><br><span class="line">~$ tree -L 1</span><br><span class="line">.</span><br><span class="line">├── cassandra</span><br><span class="line">├── code-of-conduct.md</span><br><span class="line">├── CONTRIBUTING.md</span><br><span class="line">├── guestbook</span><br><span class="line">├── guestbook-go</span><br><span class="line">├── guidelines.md</span><br><span class="line">├── LICENSE</span><br><span class="line">├── mysql-wordpress-pd</span><br><span class="line">├── OWNERS</span><br><span class="line">├── README.md</span><br><span class="line">├── SECURITY_CONTACTS</span><br><span class="line">└── staging</span><br><span class="line"></span><br><span class="line">5 directories, 7 files</span><br></pre></td></tr></table></figure>
<h3 id="安装Redis-Master-Pod"><a href="#安装Redis-Master-Pod" class="headerlink" title="安装Redis Master Pod"></a>安装<code>Redis Master Pod</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">~$ <span class="built_in">cd</span> examples/guestbook$ &amp;&amp; ls *.yaml</span><br><span class="line">frontend-deployment.yaml  redis-master-deployment.yaml  redis-slave-deployment.yaml</span><br><span class="line">frontend-service.yaml     redis-master-service.yaml     redis-slave-service.yaml</span><br><span class="line">~$ cat redis-master-deployment.yaml</span><br><span class="line">apiVersion: apps/v1 <span class="comment">#  for k8s versions before 1.9.0 use apps/v1beta2  and before 1.8.0 use extensions/v1beta1</span></span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-master</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: redis</span><br><span class="line">      role: master</span><br><span class="line">      tier: backend</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: redis</span><br><span class="line">        role: master</span><br><span class="line">        tier: backend</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: master</span><br><span class="line">        <span class="comment"># image: k8s.gcr.io/redis:e2e  # or just image: redis</span></span><br><span class="line">        image: forestgun007/redis:e2e</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 6379</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>注意</strong>上面的<code>k8.gcr.io</code>在国内是不能访问的,所以要修改<code>redis-master-deployment.yaml</code>里的<code>image</code>,<br>这里通过<code>docker search redis:e2e</code>查询到一些<code>mirror</code>的镜像文件.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~$ docker search redis:e2e</span><br><span class="line">NAME                       DESCRIPTION                          STARS               OFFICIAL            AUTOMATED</span><br><span class="line">forestgun007/redis         gcr.io/google_containers/redis:e2e   1                                       [OK]</span><br><span class="line">will835559313/gcr_redis    gcr.io/google_containers/redis:e2e   0                                       [OK]</span><br><span class="line">smallguitar/redis-master   gcr.io/google_containers/redis:e2e   0                                       [OK]</span><br><span class="line"></span><br><span class="line">~$ kubectl apply -f redis-master-deployment.yaml</span><br><span class="line">~$ kubectl get pods</span><br><span class="line">redis-slave-555b8847c4-mttt9    1/1     Running   0          16h</span><br></pre></td></tr></table></figure>
<h3 id="安装Redis-Master-Service"><a href="#安装Redis-Master-Service" class="headerlink" title="安装Redis Master Service"></a>安装<code>Redis Master Service</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">~$ cat redis-master-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-master</span><br><span class="line">  labels:</span><br><span class="line">    app: redis</span><br><span class="line">    role: master</span><br><span class="line">    tier: backend</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 6379</span><br><span class="line">    targetPort: 6379</span><br><span class="line">  selector:</span><br><span class="line">    app: redis</span><br><span class="line">    role: master</span><br><span class="line">    tier: backend</span><br><span class="line">~$ kubectl apply -f redis-master-service.yaml</span><br><span class="line">~$ kubectl get service redis-master</span><br><span class="line">NAME           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">redis-master   ClusterIP   10.106.23.86   &lt;none&gt;        6379/TCP   17h</span><br></pre></td></tr></table></figure>
<h3 id="安装Redis-Slave-Pod"><a href="#安装Redis-Slave-Pod" class="headerlink" title="安装Redis Slave Pod"></a>安装<code>Redis Slave Pod</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">$ cat redis-slave-deployment.yaml</span><br><span class="line">apiVersion: apps/v1 <span class="comment">#  for k8s versions before 1.9.0 use apps/v1beta2  and before 1.8.0 use extensions/v1beta1</span></span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-slave</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: redis</span><br><span class="line">      role: slave</span><br><span class="line">      tier: backend</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: redis</span><br><span class="line">        role: slave</span><br><span class="line">        tier: backend</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: slave</span><br><span class="line">        <span class="comment"># gcr.io/google_samples/gb-redisslave:v1 同样需要改成下面这个镜像</span></span><br><span class="line">        image: forestgun007/gb-redisslave:v1</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        env:</span><br><span class="line">        - name: GET_HOSTS_FROM</span><br><span class="line">          value: dns</span><br><span class="line">          <span class="comment"># If your cluster config does not include a dns service, then to</span></span><br><span class="line">          <span class="comment"># instead access an environment variable to find the master</span></span><br><span class="line">          <span class="comment"># service's host, comment out the 'value: dns' line above, and</span></span><br><span class="line">          <span class="comment"># uncomment the line below:</span></span><br><span class="line">          <span class="comment"># value: env</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 6379</span><br><span class="line"></span><br><span class="line">~$ kubectl apply -f redis-slave-deployment.yaml</span><br><span class="line">~$ kubectl get pods</span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">redis-slave-555b8847c4-mttt9    1/1     Running   0          17h</span><br><span class="line">redis-slave-555b8847c4-r24xx    1/1     Running   0          17h</span><br></pre></td></tr></table></figure>
<h3 id="安装Redis-Slave-Service"><a href="#安装Redis-Slave-Service" class="headerlink" title="安装Redis Slave Service"></a>安装<code>Redis Slave Service</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl apply -f  redis-slave-service.yaml</span><br><span class="line"></span><br><span class="line">~$ kubectl get svc redis-slave</span><br><span class="line">NAME          TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">redis-slave   ClusterIP   10.103.39.53   &lt;none&gt;        6379/TCP   17h</span><br></pre></td></tr></table></figure>
<h3 id="安装Frontend-Pod"><a href="#安装Frontend-Pod" class="headerlink" title="安装Frontend Pod"></a>安装<code>Frontend Pod</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">~$ cat frontend-deployment.yaml</span><br><span class="line">apiVersion: apps/v1 <span class="comment">#  for k8s versions before 1.9.0 use apps/v1beta2  and before 1.8.0 use extensions/v1beta1</span></span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: frontend</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: guestbook</span><br><span class="line">      tier: frontend</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: guestbook</span><br><span class="line">        tier: frontend</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: php-redis</span><br><span class="line">        <span class="comment"># image: gcr.io/google-samples/gb-frontend:v4</span></span><br><span class="line">        image: forestgun007/google-samples-gb-frontend:v4</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        env:</span><br><span class="line">        - name: GET_HOSTS_FROM</span><br><span class="line">          value: dns</span><br><span class="line">          <span class="comment"># If your cluster config does not include a dns service, then to</span></span><br><span class="line">          <span class="comment"># instead access environment variables to find service host</span></span><br><span class="line">          <span class="comment"># info, comment out the 'value: dns' line above, and uncomment the</span></span><br><span class="line">          <span class="comment"># line below:</span></span><br><span class="line">          <span class="comment"># value: env</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">~$ kubectl apply -f frontend-deployment.yaml</span><br><span class="line"></span><br><span class="line">~$ kubectl get pod</span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">frontend-6f4cc58c94-2wv5l       1/1     Running   0          17h</span><br><span class="line">frontend-6f4cc58c94-s6s8l       1/1     Running   0          17h</span><br><span class="line">frontend-6f4cc58c94-z9qmk       1/1     Running   0          17h</span><br></pre></td></tr></table></figure>
<h3 id="安装Frontend-Service"><a href="#安装Frontend-Service" class="headerlink" title="安装Frontend Service"></a>安装<code>Frontend Service</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl apply -f  frontend-service.yaml</span><br><span class="line">~$ kubectl get service frontend</span><br><span class="line">NAME       TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">frontend   NodePort   10.106.20.24   &lt;none&gt;        80:30577/TCP   17h</span><br></pre></td></tr></table></figure>
<h1 id="错误处理-1"><a href="#错误处理-1" class="headerlink" title="错误处理"></a>错误处理</h1><h2 id="连接证书错误"><a href="#连接证书错误" class="headerlink" title="连接证书错误"></a>连接证书错误</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get node</span><br><span class="line">Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of <span class="string">"crypto/rsa: verification error"</span> <span class="keyword">while</span> trying to verify candidate authority certificate <span class="string">"kubernetes"</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>上述错误,一般是在<code>kubeadm reset</code>后,没有更新<code>~/.kube/config</code>的文件发生.<code>cp /etc/kubernetes/admin.conf ~/.kube/conf</code>就可以解决.</li>
</ul>
<h2 id="加入节点错误"><a href="#加入节点错误" class="headerlink" title="加入节点错误"></a>加入节点错误</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo kubeadm join 172.18.127.186:6443 --token z8r97j.3ovdfddb6df9lnq7     --discovery-token-ca-cert-hash sha256:07767a67fa6c38feda7471ee5e1a15a0a9c417cfdf6cf457ff577297f22d9415</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">	[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">error execution phase preflight: couldn<span class="string">'t validate the identity of the API Server: abort connecting to API servers after timeout of 5m0s</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>如果加入节点时间很长,且最后还出错了,加参数<code>-v=6</code>,就会出现如下错误:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo kubeadm join 172.18.127.186:6443 --token z8r97j.3ovdfddb6df9lnq7     --discovery-token-ca-cert-hash sha256:07767a67fa6c38feda7471ee5e1a15a0a9c417cfdf6cf457ff577297f22d9415 -v=6</span><br><span class="line"></span><br><span class="line">[...]</span><br><span class="line">I0414 16:23:00.398178   13202 token.go:200] [discovery] Trying to connect to API Server <span class="string">"172.18.127.186:6443"</span></span><br><span class="line">I0414 16:23:00.398724   13202 token.go:75] [discovery] Created cluster-info discovery client, requesting info from <span class="string">"https://172.18.127.186:6443"</span></span><br><span class="line">I0414 16:23:00.402234   13202 round_trippers.go:438] GET https://172.18.127.186:6443/api/v1/namespaces/kube-public/configmaps/cluster-info 200 OK <span class="keyword">in</span> 3 milliseconds</span><br><span class="line">I0414 16:23:00.402426   13202 token.go:203] [discovery] Failed to connect to API Server <span class="string">"172.18.127.186:6443"</span>: token id <span class="string">"z8r97j"</span> is invalid <span class="keyword">for</span> this cluster or it has expired. Use <span class="string">"kubeadm token create"</span> on the control-plane node to create a new valid token</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果出现上述错误,在Master节点输入下面命令,用它输出的<code>kubeadm join</code>参数,在需要添加的节点为上运行.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ kubeadm  token create --<span class="built_in">print</span>-join-command</span><br><span class="line"><span class="comment"># 使用下述输出,重新添加.</span></span><br><span class="line">kubeadm join 172.18.127.186:6443 --token in1l6v.ue78pr5vvr55qcad     --discovery-token-ca-cert-hash sha256:a1f80db7a76e214dd529fc2aed660d71428994d9104c1b320bf5abb6cda4b165</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="安装charts错误"><a href="#安装charts错误" class="headerlink" title="安装charts错误"></a>安装<code>charts</code>错误</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ helm install stable/minio</span><br><span class="line">Error: could not find a ready tiller pod</span><br></pre></td></tr></table></figure>
<ul>
<li><p>第一步,更新一下仓库</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">~$ helm init --upgrade</span><br><span class="line"><span class="variable">$HELM_HOME</span> has been configured at /home/lcy/.helm.</span><br><span class="line"></span><br><span class="line">Tiller (the Helm server-side component) has been upgraded to the current version.</span><br><span class="line">Happy Helming!</span><br><span class="line"></span><br><span class="line">~$ helm repo list</span><br><span class="line">NAME    URL</span><br><span class="line">stable  https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><span class="line"><span class="built_in">local</span>   http://127.0.0.1:8879/charts</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看<code>k8s</code>的子系统<code>Pod</code>的状态,查看<code>tiller-deploy</code>部分.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl  -n kube-system get po</span><br><span class="line">NAME                                       READY   STATUS         RESTARTS   AGE</span><br><span class="line">calico-kube-controllers-5cbcccc885-krbzj   1/1     Running        0          17h</span><br><span class="line">[]...]</span><br><span class="line">kube-scheduler-k8s-master                  1/1     Running        0          18h</span><br><span class="line">tiller-deploy-c48485567-m7kj2              0/1     ErrImagePull   0          2m50s</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据上述输出,<code>tiller-deploy</code>拉取镜像失败,没有运行起,下面再查看详情.</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl  describe pod tiller-deploy-c48485567-m7kj2   -n kube-system</span><br><span class="line">Name:               tiller-deploy-c48485567-m7kj2</span><br><span class="line">[...]</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age                 From               Message</span><br><span class="line">  ----     ------     ----                ----               -------</span><br><span class="line">  Normal   Scheduled  16m                 default-scheduler  Successfully assigned kube-system/tiller-deploy-c48485567-m7kj2 to dig001</span><br><span class="line">  Normal   Pulling    14m (x4 over 16m)   kubelet, dig001    Pulling image <span class="string">"gcr.io/kubernetes-helm/tiller:v2.13.1"</span></span><br><span class="line">  Warning  Failed     13m (x4 over 16m)   kubelet, dig001    Failed to pull image <span class="string">"gcr.io/kubernetes-helm/tiller:v2.13.1"</span>: rpc error: code = Unknown desc = Error response from daemon: Get https://gcr.io/v2/: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">  Warning  Failed     13m (x4 over 16m)   kubelet, dig001    Error: ErrImagePull</span><br><span class="line">  Warning  Failed     13m (x7 over 16m)   kubelet, dig001    Error: ImagePullBackOff</span><br><span class="line">  Normal   BackOff    82s (x57 over 16m)  kubelet, dig001    Back-off pulling image <span class="string">"gcr.io/kubernetes-helm/tiller:v2.13.1"</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>因为使用要<code>gcr.io</code>的仓库造成拉取失败,下面通过<code>docker search tiller | grep &quot;Mirror&quot;</code>选取一个,再通过下面命令修改它.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl edit deploy tiller-deploy -n kube-system</span><br><span class="line">[....]</span><br></pre></td></tr></table></figure>
</li>
<li><p>将上述中的<code>image  gcr.io/kubernetes-helm/tiller:v2.13.1</code> 替换成<code>image: sapcc/tiller:v2.13.1</code>,下面再运行就会显示<code>tiller</code>成功运行.</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl get pod -n kube-system | grep <span class="string">"tiller"</span></span><br><span class="line">tiller-deploy-b7bd9495c-bf777              1/1     Running   0          2m57s</span><br><span class="line">~$ helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:<span class="string">"v2.13.1"</span>, GitCommit:<span class="string">"618447cbf203d147601b4b9bd7f8c37a5d39fbb4"</span>, GitTreeState:<span class="string">"clean"</span>&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:<span class="string">"v2.13.1"</span>, GitCommit:<span class="string">"618447cbf203d147601b4b9bd7f8c37a5d39fbb4"</span>, GitTreeState:<span class="string">"clean"</span>&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Error-no-available-release-name-found"><a href="#Error-no-available-release-name-found" class="headerlink" title="Error: no available release name found"></a>Error: no available release name found</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl create serviceaccount --namespace kube-system tiller</span><br><span class="line">~$ kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/tiller-cluster-rule created</span><br><span class="line">~$ kubectl patch deploy --namespace kube-system tiller-deploy -p \<span class="string">'&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;\'</span></span><br><span class="line">deployment.extensions/tiller-deploy patched</span><br></pre></td></tr></table></figure>
<h2 id="kubeadm初始化错误"><a href="#kubeadm初始化错误" class="headerlink" title="kubeadm初始化错误"></a><code>kubeadm</code>初始化错误</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers  --kubernetes-version v1.14.1 --pod-network-cidr=10.244.0.0/16</span><br><span class="line">[init] Using Kubernetes version: v1.14.1</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] WARNING: Couldn\<span class="string">'t create the interface used for talking to the container runtime: docker is required for container runtime: exec: "docker": executable file not found in $PATH</span></span><br><span class="line"><span class="string">error execution phase preflight: [preflight] Some fatal errors occurred:</span></span><br><span class="line"><span class="string">	[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2</span></span><br><span class="line"><span class="string">	[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist</span></span><br><span class="line"><span class="string">	[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1</span></span><br><span class="line"><span class="string">[preflight] If you know what you are doing, you can make a check non-fatal with  `--ignore-preflight-errors=...`</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>ERROR NumCPU</code>加入运行参数<code>--ignore-preflight-errors=NumCPU</code>就变成警告了.</li>
<li><p><code>FileContent--proc-sys-net-bridge-bridge-nf-call-iptables</code>错误处理如下:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">~$ apt-get install bridge-utils</span><br><span class="line"><span class="comment"># 有可能要重启</span></span><br><span class="line">~$ modprobe bridge</span><br><span class="line">~$ modprobe br_netfilter</span><br><span class="line"></span><br><span class="line">~$ cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">~$ sysctl --system</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>kube-proxy</code>与<code>iptables</code>的问题</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ kubectl -n kube-system logs  kube-proxy-xxx</span><br><span class="line">W0514 00:21:27.445425       1 server_others.go:267] Flag proxy-mode=<span class="string">""</span> unknown, assuming iptables proxy</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat mysql-pass.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: mysql-pass</span><br><span class="line"><span class="built_in">type</span>: Opaque</span><br><span class="line">data:</span><br><span class="line">  username: cm9vdA==</span><br><span class="line">  password: cGFzczEyMw==</span><br></pre></td></tr></table></figure>
<h1 id="谢谢支持"><a href="#谢谢支持" class="headerlink" title="谢谢支持"></a>谢谢支持</h1><ul>
<li>微信二维码:</li>
</ul>
<p><img src="/imgs/mm_reward_qrcode_1525013906055.png" width="40%" height="40%" align="center/"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Docker-Linux-Kubernetes/" rel="tag"># Docker,Linux,Kubernetes</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/02/02/玩转FPGA-DE0-Nano/" rel="prev" title="玩转FPGA_DE0-Nano">
      <i class="fa fa-chevron-left"></i> 玩转FPGA_DE0-Nano
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/02/19/Kubernetes基于CephFS的存储/" rel="next" title="Kubernetes基于CephFS的存储">
      Kubernetes基于CephFS的存储 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#PaaS概述"><span class="nav-number">1.</span> <span class="nav-text">PaaS概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kubernetes概述"><span class="nav-number">1.1.</span> <span class="nav-text">Kubernetes概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kubernetes的基本概念"><span class="nav-number">1.1.1.</span> <span class="nav-text">Kubernetes的基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Pod"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">Pod</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Replication-Controller"><span class="nav-number">1.1.1.2.</span> <span class="nav-text">Replication Controller</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Deployment"><span class="nav-number">1.1.1.3.</span> <span class="nav-text">Deployment</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job"><span class="nav-number">1.1.1.4.</span> <span class="nav-text">Job</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#StatefulSet"><span class="nav-number">1.1.1.5.</span> <span class="nav-text">StatefulSet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Service"><span class="nav-number">1.1.1.6.</span> <span class="nav-text">Service</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ingress"><span class="nav-number">1.1.1.7.</span> <span class="nav-text">Ingress</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Label"><span class="nav-number">1.1.1.8.</span> <span class="nav-text">Label</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Node"><span class="nav-number">1.1.1.9.</span> <span class="nav-text">Node</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kubernetes架构"><span class="nav-number">1.1.2.</span> <span class="nav-text">Kubernetes架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Master节点"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">Master节点</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#API-Server-kube-apiserver"><span class="nav-number">1.1.2.1.1.</span> <span class="nav-text">API Server(kube-apiserver)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scheduler-kube-scheduler"><span class="nav-number">1.1.2.1.2.</span> <span class="nav-text">Scheduler(kube-scheduler)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Controller-Manager-kube-controller-manager"><span class="nav-number">1.1.2.1.3.</span> <span class="nav-text">Controller Manager(kube-controller-manager)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#etcd"><span class="nav-number">1.1.2.1.4.</span> <span class="nav-text">etcd</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Pod网络"><span class="nav-number">1.1.2.1.5.</span> <span class="nav-text">Pod网络</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Node节点"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">Node节点</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#kubelet"><span class="nav-number">1.1.2.2.1.</span> <span class="nav-text">kubelet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#kube-proxy"><span class="nav-number">1.1.2.2.2.</span> <span class="nav-text">kube-proxy</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Secret-amp-ConfigMap"><span class="nav-number">1.1.2.2.3.</span> <span class="nav-text">Secret &amp; ConfigMap</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#插件"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">插件</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#网络相关"><span class="nav-number">1.1.2.3.1.</span> <span class="nav-text">网络相关</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#服务发现"><span class="nav-number">1.1.2.3.2.</span> <span class="nav-text">服务发现</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#可视化面板"><span class="nav-number">1.1.2.3.3.</span> <span class="nav-text">可视化面板</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装Minikube"><span class="nav-number">1.2.</span> <span class="nav-text">安装Minikube</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#源码编译Minikube"><span class="nav-number">2.</span> <span class="nav-text">源码编译Minikube</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#错误处理"><span class="nav-number">2.1.</span> <span class="nav-text">错误处理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#手动布署安装Kubernetes组件"><span class="nav-number">3.</span> <span class="nav-text">手动布署安装Kubernetes组件</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Debian-Ubuntu发行版安装kubeadm"><span class="nav-number">3.1.</span> <span class="nav-text">Debian,Ubuntu发行版安装kubeadm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#官方软件仓库-在国内不能使用"><span class="nav-number">3.1.1.</span> <span class="nav-text">官方软件仓库,在国内不能使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#阿里云镜像仓库"><span class="nav-number">3.1.2.</span> <span class="nav-text">阿里云镜像仓库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Master节点"><span class="nav-number">3.1.3.</span> <span class="nav-text">安装Master节点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#网络模型"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">网络模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#修改Kubelet的启动参数"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">修改Kubelet的启动参数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装集群节点"><span class="nav-number">3.1.4.</span> <span class="nav-text">安装集群节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拆除k8s集群"><span class="nav-number">3.1.5.</span> <span class="nav-text">拆除k8s集群</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#安装HelloWorld共享Pod数据"><span class="nav-number">4.</span> <span class="nav-text">安装HelloWorld共享Pod数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#通过Github安装Kubernetes"><span class="nav-number">4.1.</span> <span class="nav-text">通过Github安装Kubernetes</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Etcd"><span class="nav-number">4.1.1.</span> <span class="nav-text">Etcd</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kubernetes发布包安装"><span class="nav-number">4.1.2.</span> <span class="nav-text">Kubernetes发布包安装</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#安装Minio服务-单节点服务"><span class="nav-number">5.</span> <span class="nav-text">安装Minio服务(单节点服务)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#MinIO服务端"><span class="nav-number">5.1.</span> <span class="nav-text">MinIO服务端</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建PV-Persistent-Volume"><span class="nav-number">5.1.1.</span> <span class="nav-text">创建PV (Persistent Volume)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Minio-PVC-Persistent-Volume-Claim"><span class="nav-number">5.1.2.</span> <span class="nav-text">安装Minio PVC (Persistent Volume Claim)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Minio-Deployment"><span class="nav-number">5.1.3.</span> <span class="nav-text">安装Minio Deployment</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Minio-Service"><span class="nav-number">5.1.4.</span> <span class="nav-text">安装Minio Service</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过Ingress暴露服务"><span class="nav-number">5.2.</span> <span class="nav-text">通过Ingress暴露服务</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Traefik反向代理"><span class="nav-number">6.</span> <span class="nav-text">Traefik反向代理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#快速安装测试"><span class="nav-number">6.1.</span> <span class="nav-text">快速安装测试</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#docker-compose测试说明"><span class="nav-number">6.2.</span> <span class="nav-text">docker-compose测试说明</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#docker-compose安装MinIO"><span class="nav-number">6.2.1.</span> <span class="nav-text">docker-compose安装MinIO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MC客户端"><span class="nav-number">6.2.2.</span> <span class="nav-text">MC客户端</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#S3客户端连接测试MinIO"><span class="nav-number">6.2.3.</span> <span class="nav-text">S3客户端连接测试MinIO</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Helm包管理器"><span class="nav-number">7.</span> <span class="nav-text">Helm包管理器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装Tiller服务器"><span class="nav-number">7.1.</span> <span class="nav-text">安装Tiller服务器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用Helm-Chart部署MinIO"><span class="nav-number">7.2.</span> <span class="nav-text">使用Helm Chart部署MinIO</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装MinIO客户端"><span class="nav-number">7.2.1.</span> <span class="nav-text">安装MinIO客户端</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装集群监控DashBoard"><span class="nav-number">7.3.</span> <span class="nav-text">安装集群监控DashBoard</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Proxy加SSH转发访问方式"><span class="nav-number">7.3.1.</span> <span class="nav-text">Proxy加SSH转发访问方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#修改Service端口类型"><span class="nav-number">7.3.2.</span> <span class="nav-text">修改Service端口类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#访问认证"><span class="nav-number">7.3.3.</span> <span class="nav-text">访问认证</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建服务帐号"><span class="nav-number">7.3.3.1.</span> <span class="nav-text">创建服务帐号</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建集群角色绑定"><span class="nav-number">7.3.3.2.</span> <span class="nav-text">创建集群角色绑定</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#更新Dashboard"><span class="nav-number">7.3.4.</span> <span class="nav-text">更新Dashboard</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#官方快速入门实例教程"><span class="nav-number">8.</span> <span class="nav-text">官方快速入门实例教程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Guestbook实例"><span class="nav-number">8.1.</span> <span class="nav-text">Guestbook实例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Redis-Master-Pod"><span class="nav-number">8.1.1.</span> <span class="nav-text">安装Redis Master Pod</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Redis-Master-Service"><span class="nav-number">8.1.2.</span> <span class="nav-text">安装Redis Master Service</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Redis-Slave-Pod"><span class="nav-number">8.1.3.</span> <span class="nav-text">安装Redis Slave Pod</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Redis-Slave-Service"><span class="nav-number">8.1.4.</span> <span class="nav-text">安装Redis Slave Service</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Frontend-Pod"><span class="nav-number">8.1.5.</span> <span class="nav-text">安装Frontend Pod</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Frontend-Service"><span class="nav-number">8.1.6.</span> <span class="nav-text">安装Frontend Service</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#错误处理-1"><span class="nav-number">9.</span> <span class="nav-text">错误处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#连接证书错误"><span class="nav-number">9.1.</span> <span class="nav-text">连接证书错误</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#加入节点错误"><span class="nav-number">9.2.</span> <span class="nav-text">加入节点错误</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装charts错误"><span class="nav-number">9.3.</span> <span class="nav-text">安装charts错误</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Error-no-available-release-name-found"><span class="nav-number">9.4.</span> <span class="nav-text">Error: no available release name found</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kubeadm初始化错误"><span class="nav-number">9.5.</span> <span class="nav-text">kubeadm初始化错误</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#谢谢支持"><span class="nav-number">10.</span> <span class="nav-text">谢谢支持</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">yjdwbj</p>
  <div class="site-description" itemprop="description">最是人间留不住,朱颜辞镜花辞树</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yjdwbj</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  















  

  

</body>
</html>
